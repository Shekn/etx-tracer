//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30794723
// Cuda compilation tools, release 11.6, V11.6.55
// Based on NVVM 7.0.1
//

.version 7.6
.target sm_52
.address_size 64

	// .globl	__raygen__main
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.const .align 16 .b8 global[384];
.global .align 4 .b8 _ZZN3etx8spectrum12spectral_xyzEyE2kX[1884] = {196, 53, 8, 57, 130, 238, 24, 57, 75, 194, 43, 57, 30, 241, 64, 57, 250, 186, 88, 57, 223, 95, 115, 57, 82, 178, 136, 57, 220, 167, 153, 57, 182, 177, 172, 57, 4, 241, 193, 57, 239, 134, 217, 57, 83, 90, 243, 57, 144, 12, 8, 58, 144, 135, 24, 58, 14, 196, 43, 58, 239, 103, 66, 58, 250, 132, 93, 58, 76, 216, 124, 58, 100, 132, 143, 58, 172, 94, 161, 58, 119, 78, 179, 58, 111, 224, 196, 58, 98, 67, 215, 58, 231, 61, 236, 58, 63, 203, 2, 59, 219, 137, 18, 59, 180, 40, 38, 59, 211, 145, 61, 59, 185, 82, 88, 59, 218, 248, 117, 59, 221, 8, 139, 59, 209, 13, 156, 59, 175, 167, 174, 59, 18, 233, 195, 59, 151, 228, 220, 59, 218, 172, 250, 59, 235, 97, 15, 60, 44, 80, 36, 60, 21, 34, 59, 60, 138, 216, 82, 60, 126, 116, 106, 60, 148, 166, 128, 60, 202, 120, 140, 60, 19, 219, 153, 60, 187, 247, 169, 60, 244, 248, 189, 60, 209, 176, 214, 60, 99, 250, 243, 60, 184, 198, 10, 61, 224, 144, 29, 61, 139, 55, 50, 61, 156, 175, 72, 61, 97, 95, 97, 61, 218, 204, 124, 61, 5, 191, 141, 61, 122, 252, 158, 61, 24, 23, 178, 61, 151, 4, 199, 61, 31, 4, 222, 61, 203, 84, 247, 61, 233, 154, 9, 62, 91, 241, 24, 62, 126, 93, 41, 62, 199, 89, 58, 62, 175, 96, 75, 62, 171, 236, 91, 62, 23, 182, 107, 62, 190, 193, 122, 62, 117, 126, 132, 62, 104, 42, 139, 62, 87, 91, 145, 62, 224, 2, 151, 62, 101, 27, 156, 62, 187, 168, 160, 62, 181, 174, 164, 62, 39, 49, 168, 62, 24, 48, 171, 62, 242, 172, 173, 62, 152, 173, 175, 62, 230, 55, 177, 62, 194, 81, 178, 62, 194, 254, 178, 62, 133, 70, 179, 62, 231, 52, 179, 62, 191, 213, 178, 62, 236, 52, 178, 62, 215, 87, 177, 62, 41, 67, 176, 62, 144, 1, 175, 62, 190, 157, 173, 62, 104, 34, 172, 62, 228, 152, 170, 62, 38, 251, 168, 62, 203, 60, 167, 62, 107, 81, 165, 62, 165, 44, 163, 62, 230, 199, 160, 62, 11, 38, 158, 62, 225, 72, 155, 62, 48, 50, 152, 62, 189, 227, 148, 62, 135, 100, 145, 62, 109, 174, 141, 62, 152, 175, 137, 62, 32, 86, 133, 62, 46, 144, 128, 62, 186, 160, 118, 62, 29, 94, 107, 62, 35, 166, 95, 62, 101, 198, 83, 62, 116, 12, 72, 62, 125, 162, 60, 62, 182, 124, 49, 62, 182, 151, 38, 62, 39, 240, 27, 62, 170, 130, 17, 62, 212, 89, 7, 62, 197, 5, 251, 61, 212, 252, 231, 61, 35, 154, 213, 61, 232, 222, 195, 61, 27, 202, 178, 61, 65, 108, 162, 61, 195, 224, 146, 61, 10, 67, 132, 61, 253, 92, 109, 61, 93, 109, 84, 61, 177, 145, 61, 61, 211, 141, 40, 61, 159, 37, 21, 61, 235, 28, 3, 61, 157, 178, 228, 60, 122, 202, 197, 60, 201, 119, 169, 60, 227, 176, 143, 60, 69, 216, 112, 60, 63, 66, 71, 60, 84, 135, 34, 60, 7, 137, 2, 60, 148, 81, 206, 59, 46, 144, 160, 59, 115, 138, 119, 59, 69, 6, 65, 59, 188, 234, 30, 59, 197, 142, 18, 59, 82, 73, 29, 59, 21, 186, 63, 59, 204, 110, 123, 59, 180, 145, 169, 59, 239, 201, 228, 59, 7, 95, 24, 60, 168, 14, 71, 60, 52, 138, 126, 60, 82, 143, 159, 60, 124, 140, 196, 60, 32, 99, 238, 60, 4, 154, 14, 61, 157, 109, 40, 61, 246, 139, 68, 61, 174, 212, 98, 61, 180, 147, 129, 61, 96, 181, 146, 61, 99, 201, 164, 61, 150, 201, 183, 61, 211, 175, 203, 61, 247, 117, 224, 61, 83, 26, 246, 61, 225, 66, 6, 62, 228, 200, 17, 62, 245, 139, 29, 62, 213, 120, 41, 62, 227, 130, 53, 62, 235, 173, 65, 62, 90, 255, 77, 62, 144, 124, 90, 62, 251, 42, 103, 62, 101, 10, 116, 62, 212, 139, 128, 62, 252, 41, 135, 62, 70, 224, 141, 62, 79, 175, 148, 62, 161, 151, 155, 62, 224, 152, 162, 62, 75, 178, 169, 62, 31, 227, 176, 62, 153, 42, 184, 62, 237, 135, 191, 62, 197, 251, 198, 62, 157, 135, 206, 62, 237, 44, 214, 62, 37, 237, 221, 62, 127, 200, 229, 62, 115, 189, 237, 62, 243, 202, 245, 62, 243, 239, 253, 62, 183, 21, 3, 63, 102, 62, 7, 63, 233, 112, 11, 63, 107, 171, 15, 63, 28, 236, 19, 63, 39, 49, 24, 63, 249, 120, 28, 63, 6, 195, 32, 63, 1, 15, 37, 63, 162, 92, 41, 63, 159, 171, 45, 63, 50, 251, 49, 63, 121, 73, 54, 63, 127, 148, 58, 63, 82, 218, 62, 63, 252, 24, 67, 63, 155, 78, 71, 63, 177, 121, 75, 63, 223, 152, 79, 63, 202, 170, 83, 63, 20, 174, 87, 63, 119, 161, 91, 63, 71, 130, 95, 63, 12, 77, 99, 63, 82, 254, 102, 63, 163, 146, 106, 63, 87, 7, 110, 63, 60, 91, 113, 63, 19, 141, 116, 63, 152, 155, 119, 63, 136, 133, 122, 63, 96, 72, 125, 63, 110, 226, 127, 63, 214, 41, 129, 63, 9, 78, 130, 63, 204, 93, 131, 63, 140, 89, 132, 63, 7, 63, 133, 63, 66, 10, 134, 63, 59, 183, 134, 63, 242, 65, 135, 63, 88, 167, 135, 63, 9, 233, 135, 63, 14, 10, 136, 63, 108, 13, 136, 63, 43, 246, 135, 63, 44, 198, 135, 63, 20, 123, 135, 63, 152, 17, 135, 63, 104, 134, 134, 63, 57, 214, 133, 63, 41, 255, 132, 63, 161, 3, 132, 63, 186, 230, 130, 63, 140, 171, 129, 63, 50, 85, 128, 63, 67, 202, 125, 63, 118, 181, 122, 63, 254, 107, 119, 63, 215, 237, 115, 63, 251, 58, 112, 63, 113, 86, 108, 63, 37, 65, 104, 63, 240, 247, 99, 63, 175, 119, 95, 63, 59, 189, 90, 63, 17, 200, 85, 63, 77, 160, 80, 63, 198, 79, 75, 63, 80, 224, 69, 63, 192, 91, 64, 63, 254, 197, 58, 63, 138, 36, 53, 63, 160, 131, 47, 63, 122, 239, 41, 63, 84, 116, 36, 63, 154, 27, 31, 63, 152, 226, 25, 63, 79, 195, 20, 63, 194, 183, 15, 63, 245, 185, 10, 63, 21, 201, 5, 63, 107, 232, 0, 63, 80, 48, 248, 62, 248, 176, 238, 62, 38, 83, 229, 62, 200, 22, 220, 62, 130, 254, 210, 62, 199, 14, 202, 62, 11, 76, 193, 62, 199, 186, 184, 62, 147, 92, 176, 62, 91, 51, 168, 62, 13, 68, 160, 62, 154, 147, 152, 62, 233, 38, 145, 62, 199, 1, 138, 62, 243, 33, 131, 62, 178, 6, 121, 62, 192, 67, 108, 62, 229, 242, 95, 62, 67, 17, 84, 62, 23, 160, 72, 62, 106, 157, 61, 62, 61, 7, 51, 62, 140, 219, 40, 62, 115, 24, 31, 62, 81, 189, 21, 62, 46, 202, 12, 62, 8, 63, 4, 62, 181, 55, 248, 61, 238, 187, 232, 61, 82, 10, 218, 61, 128, 42, 204, 61, 30, 36, 191, 61, 197, 254, 178, 61, 177, 187, 167, 61, 144, 75, 157, 61, 43, 157, 147, 61, 75, 159, 138, 61, 184, 64, 130, 61, 7, 248, 116, 61, 31, 136, 102, 61, 41, 248, 88, 61, 153, 14, 76, 61, 230, 145, 63, 61, 231, 86, 51, 61, 236, 108, 39, 61, 14, 242, 27, 61, 109, 4, 17, 61, 39, 194, 6, 61, 193, 97, 250, 60, 89, 126, 232, 60, 34, 209, 215, 60, 34, 81, 200, 60, 90, 245, 185, 60, 246, 184, 172, 60, 237, 143, 160, 60, 111, 102, 149, 60, 173, 40, 139, 60, 227, 194, 129, 60, 113, 84, 114, 60, 195, 156, 98, 60, 179, 38, 84, 60, 141, 185, 70, 60, 197, 27, 58, 60, 186, 38, 46, 60, 139, 214, 34, 60, 119, 46, 24, 60, 193, 49, 14, 60, 166, 227, 4, 60, 174, 117, 248, 59, 182, 72, 232, 59, 238, 41, 217, 59, 217, 2, 203, 59, 241, 188, 189, 59, 233, 68, 177, 59, 35, 144, 165, 59, 92, 149, 154, 59, 75, 75, 144, 59, 160, 168, 134, 59, 99, 66, 123, 59, 25, 87, 106, 59, 250, 132, 90, 59, 159, 193, 75, 59, 163, 2, 62, 59, 110, 59, 49, 59, 64, 89, 37, 59, 99, 72, 26, 59, 26, 245, 15, 59, 180, 75, 6, 59, 45, 121, 250, 58, 36, 127, 233, 58, 12, 152, 217, 58, 142, 178, 202, 58, 105, 189, 188, 58, 89, 164, 175, 58, 13, 90, 163, 58, 214, 215, 151, 58, 255, 22, 141, 58, 187, 16, 131, 58, 104, 118, 115, 58, 234, 20, 98, 58, 113, 233, 81, 58, 118, 224, 66, 58, 100, 230, 52, 58, 70, 232, 39, 58, 92, 216, 27, 58, 2, 171, 16, 58, 135, 84, 6, 58, 127, 146, 249, 57, 30, 249, 231, 57, 42, 192, 215, 57, 229, 202, 200, 57, 162, 252, 186, 57, 179, 56, 174, 57, 24, 103, 162, 57, 197, 117, 151, 57, 247, 80, 141, 57, 234, 228, 131, 57, 167, 59, 118, 57, 68, 209, 101, 57, 250, 117, 86, 57, 91, 28, 72, 57, 17, 183, 58, 57, 175, 56, 46, 57, 213, 141, 34, 57, 165, 165, 23, 57, 147, 118, 13, 57, 36, 247, 3, 57, 160, 59, 246, 56, 4, 191, 229, 56, 92, 97, 214, 56, 129, 14, 200, 56, 88, 178, 186, 56, 178, 56, 174, 56, 79, 142, 162, 56, 197, 166, 151, 56, 31, 120, 141, 56, 115, 248, 131, 56, 165, 59, 118, 56, 36, 185, 101, 56, 84, 83, 86, 56, 76, 248, 71, 56, 32, 150, 58, 56, 245, 26, 46, 56, 128, 117, 34, 56, 54, 151, 23, 56, 91, 114, 13, 56, 38, 249, 3, 56, 165, 59, 246, 55, 239, 164, 229, 55, 21, 29, 214, 55, 182, 152, 199, 55, 101, 12, 186, 55, 182, 108, 173, 55, 221, 170, 161, 55, 141, 182, 150, 55, 40, 130, 140, 55, 35, 0, 131, 55, 188, 69, 116, 55, 84, 187, 99, 55, 16, 78, 84, 55, 184, 236, 69, 55, 241, 133, 56, 55, 130, 8, 44, 55, 94, 98, 32, 55, 240, 132, 21, 55, 32, 100, 11, 55, 211, 243, 1, 55, 214, 79, 242, 54, 133, 231, 225, 54, 16, 154, 210, 54, 82, 86, 196, 54, 27, 11, 183, 54, 70, 167, 170, 54, 226, 24, 159, 54, 138, 81, 148, 54, 66, 69, 138, 54, 23, 232, 128, 54, 80, 92, 112, 54, 196, 21, 96, 54, 14, 232, 80, 54, 15, 194, 66, 54, 161, 146, 53, 54, 166, 72, 41, 54, 88, 210, 29, 54, 103, 33, 19, 54, 248, 41, 9, 54, 97, 192, 255, 53, 98, 112, 238, 53, 29, 75, 222, 53, 49, 60, 207, 53, 200, 50, 193, 53, 251, 29, 180, 53, 225, 236, 167, 53};
.global .align 4 .b8 _ZZN3etx8spectrum12spectral_xyzEyE2kY[1884] = {198, 110, 131, 54, 147, 108, 147, 54, 250, 104, 165, 54, 176, 160, 185, 54, 107, 80, 208, 54, 229, 180, 233, 54, 133, 21, 3, 55, 108, 23, 19, 55, 207, 21, 37, 55, 80, 70, 57, 55, 165, 222, 79, 55, 173, 249, 104, 55, 1, 129, 130, 55, 121, 82, 146, 55, 200, 71, 164, 55, 151, 183, 184, 55, 190, 94, 208, 55, 38, 58, 235, 55, 50, 64, 4, 56, 11, 180, 19, 56, 238, 147, 35, 56, 127, 160, 51, 56, 43, 198, 68, 56, 233, 97, 88, 56, 177, 208, 111, 56, 189, 55, 134, 56, 129, 183, 151, 56, 92, 105, 172, 56, 208, 25, 196, 56, 99, 149, 222, 56, 130, 168, 251, 56, 126, 138, 13, 57, 211, 217, 30, 57, 221, 121, 50, 57, 55, 34, 73, 57, 126, 138, 99, 57, 66, 115, 129, 57, 101, 115, 147, 57, 8, 255, 166, 57, 134, 79, 187, 57, 56, 158, 207, 57, 52, 100, 227, 57, 53, 0, 248, 57, 18, 194, 7, 58, 242, 0, 22, 58, 172, 197, 39, 58, 102, 240, 61, 58, 94, 102, 88, 58, 46, 184, 118, 58, 55, 59, 140, 58, 221, 152, 158, 58, 49, 136, 178, 58, 132, 163, 200, 58, 249, 125, 225, 58, 170, 170, 253, 58, 85, 222, 14, 59, 182, 224, 32, 59, 58, 36, 53, 59, 1, 84, 76, 59, 45, 27, 103, 59, 111, 18, 131, 59, 160, 248, 148, 59, 131, 15, 169, 59, 139, 3, 191, 59, 44, 129, 214, 59, 215, 52, 239, 59, 69, 125, 4, 60, 225, 245, 17, 60, 159, 8, 32, 60, 221, 185, 46, 60, 237, 13, 62, 60, 178, 255, 77, 60, 15, 138, 94, 60, 83, 177, 111, 60, 239, 188, 128, 60, 10, 244, 137, 60, 44, 132, 147, 60, 175, 103, 157, 60, 251, 142, 167, 60, 115, 234, 177, 60, 127, 106, 188, 60, 125, 5, 199, 60, 145, 204, 209, 60, 56, 216, 220, 60, 225, 64, 232, 60, 33, 31, 244, 60, 201, 63, 0, 61, 10, 177, 6, 61, 5, 102, 13, 61, 105, 97, 20, 61, 227, 165, 27, 61, 67, 54, 35, 61, 236, 20, 43, 61, 250, 67, 51, 61, 134, 197, 59, 61, 166, 155, 68, 61, 81, 204, 77, 61, 212, 86, 87, 61, 76, 51, 97, 61, 214, 89, 107, 61, 143, 194, 117, 61, 118, 53, 128, 61, 56, 176, 133, 61, 165, 89, 139, 61, 213, 57, 145, 61, 226, 88, 151, 61, 145, 186, 157, 61, 182, 98, 164, 61, 128, 89, 171, 61, 28, 167, 178, 61, 185, 83, 186, 61, 34, 100, 194, 61, 140, 216, 202, 61, 74, 178, 211, 61, 154, 242, 220, 61, 212, 154, 230, 61, 158, 180, 240, 61, 183, 60, 251, 61, 139, 16, 3, 62, 218, 167, 8, 62, 66, 91, 14, 62, 13, 38, 20, 62, 160, 20, 26, 62, 140, 55, 32, 62, 120, 159, 38, 62, 251, 92, 45, 62, 18, 121, 52, 62, 168, 246, 59, 62, 51, 221, 67, 62, 59, 52, 76, 62, 50, 3, 85, 62, 174, 84, 94, 62, 23, 45, 104, 62, 171, 138, 114, 62, 182, 107, 125, 62, 56, 103, 132, 62, 173, 85, 138, 62, 211, 136, 144, 62, 220, 16, 151, 62, 240, 253, 157, 62, 66, 96, 165, 62, 10, 67, 173, 62, 97, 153, 181, 62, 71, 79, 190, 62, 177, 80, 199, 62, 160, 137, 208, 62, 42, 236, 217, 62, 140, 124, 227, 62, 8, 66, 237, 62, 217, 67, 247, 62, 156, 196, 0, 63, 163, 8, 6, 63, 35, 101, 11, 63, 15, 209, 16, 63, 92, 67, 22, 63, 255, 178, 27, 63, 203, 28, 33, 63, 130, 122, 38, 63, 122, 190, 43, 63, 12, 219, 48, 63, 143, 194, 53, 63, 88, 106, 58, 63, 180, 214, 62, 63, 109, 16, 67, 63, 80, 32, 71, 63, 40, 15, 75, 63, 83, 224, 78, 63, 28, 143, 82, 63, 52, 24, 86, 63, 72, 120, 89, 63, 8, 172, 92, 63, 17, 178, 95, 63, 229, 140, 98, 63, 18, 63, 101, 63, 32, 203, 103, 63, 158, 51, 106, 63, 226, 121, 108, 63, 156, 157, 110, 63, 196, 158, 112, 63, 90, 125, 114, 63, 88, 57, 116, 63, 88, 211, 117, 63, 67, 76, 119, 63, 137, 164, 120, 63, 156, 220, 121, 63, 241, 244, 122, 63, 123, 237, 123, 63, 145, 203, 124, 63, 36, 133, 125, 63, 231, 40, 126, 63, 13, 181, 126, 63, 112, 40, 127, 63, 95, 131, 127, 63, 206, 197, 127, 63, 127, 239, 127, 63, 0, 0, 128, 63, 156, 246, 127, 63, 109, 210, 127, 63, 67, 146, 127, 63, 193, 52, 127, 63, 82, 184, 126, 63, 17, 27, 126, 63, 197, 95, 125, 63, 159, 135, 124, 63, 206, 147, 123, 63, 136, 133, 122, 63, 141, 93, 121, 63, 155, 27, 120, 63, 82, 191, 118, 63, 84, 72, 117, 63, 70, 182, 115, 63, 10, 9, 114, 63, 124, 65, 112, 63, 175, 96, 110, 63, 184, 103, 108, 63, 168, 87, 106, 63, 146, 49, 104, 63, 127, 245, 101, 63, 237, 162, 99, 63, 94, 57, 97, 63, 82, 184, 94, 63, 223, 31, 92, 63, 193, 113, 89, 63, 238, 175, 86, 63, 94, 220, 83, 63, 9, 249, 80, 63, 7, 7, 78, 63, 108, 7, 75, 63, 51, 252, 71, 63, 83, 231, 68, 63, 193, 202, 65, 63, 52, 168, 62, 63, 9, 128, 59, 63, 40, 82, 56, 63, 126, 30, 53, 63, 247, 228, 49, 63, 235, 165, 46, 63, 126, 98, 43, 63, 208, 27, 40, 63, 3, 211, 36, 63, 55, 137, 33, 63, 112, 63, 30, 63, 226, 245, 26, 63, 123, 172, 23, 63, 38, 99, 20, 63, 206, 25, 17, 63, 101, 208, 13, 63, 248, 135, 10, 63, 33, 66, 7, 63, 122, 0, 4, 63, 156, 196, 0, 63, 186, 30, 251, 62, 103, 192, 244, 62, 75, 109, 238, 62, 119, 36, 232, 62, 247, 228, 225, 62, 96, 176, 219, 62, 190, 133, 213, 62, 91, 96, 207, 62, 126, 59, 201, 62, 111, 18, 195, 62, 223, 226, 188, 62, 14, 178, 182, 62, 150, 134, 176, 62, 18, 103, 170, 62, 29, 90, 164, 62, 144, 97, 158, 62, 217, 127, 152, 62, 101, 188, 146, 62, 168, 30, 141, 62, 20, 174, 135, 62, 82, 112, 130, 62, 87, 196, 122, 62, 128, 251, 112, 62, 99, 122, 103, 62, 63, 53, 94, 62, 81, 40, 85, 62, 133, 86, 76, 62, 48, 190, 67, 62, 164, 93, 59, 62, 51, 51, 51, 62, 163, 60, 43, 62, 89, 122, 35, 62, 169, 238, 27, 62, 226, 155, 20, 62, 77, 132, 13, 62, 4, 168, 6, 62, 128, 6, 0, 62, 130, 66, 243, 61, 124, 243, 230, 61, 209, 34, 219, 61, 193, 210, 207, 61, 141, 254, 196, 61, 173, 158, 186, 61, 160, 171, 176, 61, 231, 29, 167, 61, 109, 241, 157, 61, 140, 37, 149, 61, 223, 183, 140, 61, 2, 166, 132, 61, 35, 219, 121, 61, 74, 24, 107, 61, 246, 255, 92, 61, 74, 143, 79, 61, 108, 195, 66, 61, 133, 153, 54, 61, 49, 11, 43, 61, 141, 23, 32, 61, 247, 195, 21, 61, 205, 21, 12, 61, 111, 18, 3, 61, 38, 116, 245, 60, 251, 0, 230, 60, 172, 176, 215, 60, 137, 104, 202, 60, 237, 13, 190, 60, 135, 151, 178, 60, 247, 241, 167, 60, 91, 243, 157, 60, 215, 113, 148, 60, 150, 67, 139, 60, 170, 72, 130, 60, 165, 23, 115, 60, 49, 70, 98, 60, 248, 72, 82, 60, 27, 76, 67, 60, 219, 87, 53, 60, 185, 81, 40, 60, 155, 49, 28, 60, 121, 239, 16, 60, 60, 131, 6, 60, 233, 208, 249, 59, 216, 44, 232, 59, 79, 253, 215, 59, 88, 37, 201, 59, 1, 136, 187, 59, 212, 20, 175, 59, 198, 179, 163, 59, 133, 60, 153, 59, 187, 134, 143, 59, 18, 106, 134, 59, 142, 142, 123, 59, 23, 55, 107, 59, 117, 210, 91, 59, 91, 101, 77, 59, 119, 244, 63, 59, 89, 114, 51, 59, 152, 195, 39, 59, 249, 215, 28, 59, 63, 159, 18, 59, 41, 9, 9, 59, 192, 7, 0, 59, 191, 38, 239, 58, 169, 74, 223, 58, 210, 109, 208, 58, 199, 130, 194, 58, 250, 119, 181, 58, 196, 63, 169, 58, 160, 210, 157, 58, 10, 41, 147, 58, 126, 59, 137, 58, 233, 0, 128, 58, 122, 215, 110, 58, 121, 219, 94, 58, 84, 241, 79, 58, 143, 252, 65, 58, 171, 230, 52, 58, 206, 163, 40, 58, 127, 39, 29, 58, 67, 101, 18, 58, 156, 80, 8, 58, 201, 181, 253, 57, 16, 245, 235, 57, 88, 85, 219, 57, 231, 204, 203, 57, 6, 82, 189, 57, 105, 214, 175, 57, 211, 72, 163, 57, 38, 155, 151, 57, 70, 191, 140, 57, 15, 167, 130, 57, 162, 137, 114, 57, 58, 29, 97, 57, 19, 248, 80, 57, 79, 9, 66, 57, 14, 64, 52, 57, 27, 138, 39, 57, 177, 210, 27, 57, 14, 5, 17, 57, 121, 12, 7, 57, 130, 168, 251, 56, 29, 150, 234, 56, 169, 199, 218, 56, 167, 32, 204, 56, 129, 132, 190, 56, 167, 214, 177, 56, 139, 251, 165, 56, 54, 228, 154, 56, 255, 134, 144, 56, 60, 218, 134, 56, 130, 168, 123, 56, 19, 206, 106, 56, 208, 12, 91, 56, 252, 86, 76, 56, 217, 158, 62, 56, 167, 214, 49, 56, 88, 238, 37, 56, 79, 213, 26, 56, 253, 124, 16, 56, 211, 214, 6, 56, 130, 168, 251, 55, 192, 206, 234, 55, 113, 14, 219, 55, 56, 89, 204, 55, 186, 160, 190, 55, 167, 214, 177, 55, 29, 234, 165, 55, 50, 203, 154, 55, 242, 108, 144, 55, 114, 194, 134, 55, 143, 125, 123, 55, 233, 170, 106, 55, 251, 247, 90, 55, 227, 80, 76, 55, 189, 161, 62, 55, 167, 214, 49, 55, 133, 219, 37, 55, 5, 164, 26, 55, 234, 39, 16, 55, 247, 94, 6, 55, 224, 129, 250, 54, 58, 134, 233, 54, 116, 179, 217, 54, 238, 245, 202, 54, 11, 58, 189, 54, 40, 108, 176, 54, 228, 121, 164, 54, 153, 85, 153, 54, 202, 242, 142, 54, 250, 68, 133, 54, 86, 127, 120, 54, 181, 171, 103, 54, 2, 250, 87, 54, 195, 88, 73, 54, 123, 182, 59, 54, 170, 1, 47, 54, 11, 40, 35, 54, 181, 26, 24, 54, 73, 205, 13, 54, 93, 51, 4, 54, 24, 129, 246, 53, 198, 207, 229, 53, 250, 61, 214, 53, 98, 186, 199, 53, 191, 51, 186, 53, 227, 152, 173, 53, 169, 215, 161, 53, 66, 225, 150, 53, 81, 169, 140, 53, 115, 35, 131, 53, 162, 134, 116, 53, 27, 248, 99, 53, 171, 134, 84, 53, 48, 33, 70, 53, 140, 182, 56, 53, 155, 53, 44, 53, 102, 140, 32, 53, 60, 172, 21, 53, 239, 136, 11, 53, 78, 22, 2, 53, 75, 144, 242, 52};
.global .align 4 .b8 _ZZN3etx8spectrum12spectral_xyzEyE2kZ[1884] = {175, 226, 30, 58, 8, 125, 50, 58, 13, 148, 72, 58, 117, 114, 97, 58, 242, 98, 125, 58, 29, 88, 142, 58, 18, 252, 159, 58, 36, 237, 179, 58, 235, 81, 202, 58, 251, 80, 227, 58, 237, 16, 255, 58, 9, 185, 14, 59, 24, 162, 31, 59, 145, 10, 51, 59, 88, 185, 73, 59, 96, 117, 100, 59, 159, 66, 130, 59, 170, 203, 148, 59, 32, 7, 169, 59, 80, 38, 190, 59, 136, 90, 211, 59, 83, 26, 232, 59, 221, 205, 253, 59, 106, 72, 11, 60, 118, 63, 26, 60, 222, 217, 44, 60, 52, 12, 68, 60, 223, 188, 95, 60, 5, 101, 127, 60, 210, 62, 145, 60, 235, 63, 164, 60, 190, 105, 184, 60, 69, 118, 206, 60, 223, 170, 231, 60, 120, 166, 2, 61, 240, 80, 20, 61, 151, 186, 41, 61, 67, 147, 66, 61, 207, 172, 93, 61, 18, 217, 121, 61, 242, 244, 138, 61, 73, 140, 152, 61, 228, 160, 166, 61, 47, 150, 182, 61, 151, 207, 201, 61, 138, 176, 225, 61, 66, 53, 255, 61, 64, 26, 17, 62, 191, 44, 37, 62, 172, 167, 59, 62, 170, 96, 84, 62, 251, 76, 111, 62, 0, 117, 134, 62, 178, 236, 150, 62, 108, 94, 169, 62, 9, 27, 190, 62, 92, 25, 213, 62, 83, 81, 238, 62, 184, 10, 5, 63, 25, 92, 20, 63, 11, 70, 37, 63, 142, 238, 55, 63, 103, 245, 75, 63, 130, 186, 96, 63, 203, 157, 117, 63, 152, 255, 132, 63, 91, 196, 142, 63, 172, 32, 152, 63, 47, 10, 161, 63, 134, 118, 169, 63, 87, 91, 177, 63, 69, 168, 184, 63, 185, 85, 191, 63, 126, 102, 197, 63, 95, 221, 202, 63, 39, 189, 207, 63, 19, 5, 212, 63, 199, 183, 215, 63, 43, 221, 218, 63, 41, 125, 221, 63, 169, 159, 223, 63, 36, 73, 225, 63, 4, 131, 226, 63, 156, 92, 227, 63, 62, 229, 227, 63, 61, 44, 228, 63, 77, 56, 228, 63, 189, 14, 228, 63, 196, 188, 227, 63, 157, 79, 227, 63, 128, 212, 226, 63, 79, 86, 226, 63, 8, 204, 225, 63, 18, 37, 225, 63, 209, 80, 224, 63, 171, 62, 223, 63, 71, 229, 221, 63, 20, 69, 220, 63, 36, 92, 218, 63, 138, 40, 216, 63, 88, 168, 213, 63, 56, 226, 210, 63, 253, 203, 207, 63, 117, 74, 204, 63, 116, 66, 200, 63, 200, 152, 195, 63, 230, 56, 190, 63, 62, 66, 184, 63, 150, 231, 177, 63, 181, 91, 171, 63, 99, 209, 164, 63, 219, 99, 158, 63, 160, 10, 152, 63, 236, 194, 145, 63, 248, 137, 139, 63, 251, 92, 133, 63, 188, 131, 126, 63, 90, 133, 114, 63, 161, 197, 102, 63, 103, 75, 91, 63, 127, 29, 80, 63, 159, 64, 69, 63, 229, 188, 58, 63, 45, 158, 48, 63, 89, 240, 38, 63, 72, 191, 29, 63, 125, 19, 21, 63, 19, 232, 12, 63, 216, 52, 5, 63, 35, 227, 251, 62, 19, 44, 238, 62, 204, 61, 225, 62, 4, 22, 213, 62, 237, 170, 201, 62, 196, 242, 190, 62, 189, 227, 180, 62, 123, 114, 171, 62, 48, 150, 162, 62, 233, 72, 154, 62, 177, 132, 146, 62, 150, 67, 139, 62, 173, 131, 132, 62, 64, 102, 124, 62, 5, 104, 112, 62, 241, 208, 100, 62, 44, 101, 89, 62, 76, 255, 77, 62, 182, 174, 66, 62, 221, 134, 55, 62, 52, 155, 44, 62, 46, 255, 33, 62, 145, 177, 23, 62, 99, 178, 13, 62, 14, 23, 4, 62, 239, 233, 245, 61, 248, 194, 228, 61, 10, 204, 212, 61, 154, 249, 197, 61, 220, 72, 184, 61, 23, 183, 171, 61, 136, 65, 160, 61, 152, 238, 149, 61, 35, 167, 140, 61, 37, 60, 132, 61, 52, 253, 120, 61, 253, 126, 106, 61, 207, 202, 92, 61, 181, 219, 79, 61, 102, 152, 67, 61, 149, 231, 55, 61, 247, 175, 44, 61, 99, 210, 33, 61, 211, 73, 23, 61, 54, 36, 13, 61, 118, 111, 3, 61, 4, 115, 244, 60, 225, 3, 227, 60, 37, 125, 210, 60, 74, 221, 194, 60, 205, 34, 180, 60, 48, 76, 166, 60, 153, 86, 153, 60, 168, 59, 141, 60, 119, 244, 129, 60, 74, 244, 110, 60, 172, 139, 91, 60, 68, 164, 73, 60, 133, 43, 57, 60, 39, 8, 42, 60, 206, 32, 28, 60, 40, 92, 15, 60, 18, 166, 3, 60, 89, 225, 241, 59, 16, 88, 222, 59, 103, 144, 204, 59, 125, 106, 188, 59, 210, 201, 173, 59, 128, 142, 160, 59, 160, 147, 148, 59, 73, 180, 137, 59, 36, 151, 127, 59, 54, 115, 109, 59, 73, 229, 92, 59, 242, 223, 77, 59, 198, 85, 64, 59, 84, 57, 52, 59, 117, 108, 41, 59, 235, 208, 31, 59, 77, 89, 23, 59, 48, 248, 15, 59, 39, 160, 9, 59, 241, 59, 4, 59, 191, 90, 255, 58, 42, 179, 247, 58, 118, 75, 241, 58, 250, 237, 235, 58, 22, 130, 231, 58, 228, 198, 227, 58, 88, 74, 224, 58, 91, 154, 220, 58, 217, 68, 216, 58, 25, 11, 211, 58, 142, 12, 205, 58, 253, 99, 198, 58, 63, 44, 191, 58, 52, 128, 183, 58, 26, 51, 175, 58, 33, 118, 166, 58, 23, 241, 157, 58, 195, 75, 150, 58, 224, 45, 144, 58, 250, 22, 140, 58, 5, 140, 137, 58, 248, 188, 135, 58, 201, 217, 133, 58, 111, 18, 131, 58, 84, 236, 125, 58, 224, 197, 115, 58, 130, 125, 104, 58, 63, 223, 92, 58, 23, 183, 81, 58, 41, 123, 71, 58, 88, 181, 61, 58, 80, 207, 51, 58, 191, 50, 41, 58, 82, 73, 29, 58, 182, 158, 15, 58, 184, 222, 0, 58, 102, 70, 228, 57, 7, 12, 201, 57, 7, 66, 178, 57, 215, 22, 161, 57, 24, 117, 148, 57, 193, 42, 139, 57, 207, 5, 132, 57, 130, 168, 123, 57, 121, 178, 112, 57, 153, 91, 103, 57, 148, 65, 94, 57, 20, 2, 84, 57, 189, 58, 71, 57, 7, 173, 54, 57, 75, 51, 35, 57, 124, 144, 14, 57, 35, 15, 245, 56, 23, 183, 209, 56, 123, 162, 180, 56, 146, 114, 156, 56, 156, 80, 136, 56, 179, 203, 110, 56, 21, 183, 81, 56, 112, 56, 57, 56, 84, 151, 37, 56, 15, 210, 21, 56, 239, 230, 8, 56, 130, 168, 251, 55, 19, 249, 231, 55, 175, 105, 214, 55, 131, 78, 198, 55, 197, 251, 182, 55, 172, 197, 167, 55, 8, 29, 152, 55, 60, 229, 135, 55, 137, 60, 110, 55, 65, 144, 75, 55, 172, 197, 39, 55, 106, 190, 1, 55, 166, 49, 181, 54, 149, 191, 86, 54, 249, 244, 178, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
.global .align 1 .b8 _ZN37_INTERNAL_35d1851d_7_test_cu_7fde99636thrust6system6detail10sequential3seqE[1];
.global .align 1 .b8 $str[32] = {67, 111, 110, 100, 105, 116, 105, 111, 110, 32, 37, 115, 32, 102, 97, 105, 108, 101, 100, 32, 97, 116, 32, 37, 115, 32, 91, 37, 117, 93, 10, 0};
.global .align 1 .b8 $str$1[10] = {99, 111, 117, 110, 116, 32, 62, 32, 48, 0};
.global .align 1 .b8 $str$2[69] = {67, 58, 47, 68, 101, 118, 101, 108, 111, 112, 109, 101, 110, 116, 47, 112, 114, 105, 118, 97, 116, 101, 47, 101, 116, 120, 45, 116, 114, 97, 99, 101, 114, 47, 115, 111, 117, 114, 99, 101, 115, 47, 101, 116, 120, 47, 114, 101, 110, 100, 101, 114, 47, 115, 104, 97, 114, 101, 100, 47, 98, 97, 115, 101, 46, 104, 120, 120, 0};
.global .align 1 .b8 $str$3[13] = {97, 32, 33, 61, 32, 110, 117, 108, 108, 112, 116, 114, 0};
.global .align 1 .b8 $str$4[10] = {105, 32, 60, 32, 99, 111, 117, 110, 116, 0};
.global .align 1 .b8 $str$5[30] = {86, 97, 108, 105, 100, 97, 116, 105, 111, 110, 32, 102, 97, 105, 108, 101, 100, 32, 91, 37, 115, 44, 32, 37, 117, 93, 58, 10, 32, 0};
.global .align 1 .b8 $str$6[70] = {67, 58, 47, 68, 101, 118, 101, 108, 111, 112, 109, 101, 110, 116, 47, 112, 114, 105, 118, 97, 116, 101, 47, 101, 116, 120, 45, 116, 114, 97, 99, 101, 114, 47, 115, 111, 117, 114, 99, 101, 115, 47, 101, 116, 120, 47, 114, 101, 110, 100, 101, 114, 47, 115, 104, 97, 114, 101, 100, 47, 105, 109, 97, 103, 101, 46, 104, 120, 120, 0};
.global .align 1 .b8 $str$7[4] = {112, 48, 48, 0};
.global .align 1 .b8 $str$8[14] = {105, 110, 118, 97, 108, 105, 100, 32, 118, 97, 108, 117, 101, 0};
.global .align 1 .b8 $str$9[4] = {112, 48, 49, 0};
.global .align 1 .b8 $str$10[4] = {112, 49, 48, 0};
.global .align 1 .b8 $str$11[4] = {112, 49, 49, 0};
.global .align 1 .b8 $str$12[26] = {37, 115, 32, 58, 32, 37, 115, 32, 40, 37, 102, 44, 32, 37, 102, 44, 32, 37, 102, 44, 32, 37, 102, 41, 10, 0};
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry __raygen__main()
{
	.local .align 16 .b8 	__local_depot0[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<208>;
	.reg .b16 	%rs<51>;
	.reg .f32 	%f<607>;
	.reg .b32 	%r<923>;
	.reg .f64 	%fd<29>;
	.reg .b64 	%rd<485>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd80, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	// begin inline asm
	call (%r173), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r174), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r176), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r177), _optix_get_launch_dimension_y, ();
	// end inline asm
	mad.lo.s32 	%r1, %r176, %r174, %r173;
	add.s32 	%r179, %r1, -176720271;
	shl.b32 	%r180, %r179, 4;
	add.s32 	%r181, %r180, -1383041155;
	add.s32 	%r182, %r1, -1817251798;
	xor.b32  	%r183, %r181, %r182;
	shr.u32 	%r184, %r179, 5;
	add.s32 	%r185, %r184, 2123724318;
	xor.b32  	%r186, %r183, %r185;
	shl.b32 	%r187, %r186, 4;
	add.s32 	%r188, %r187, -1556008596;
	add.s32 	%r189, %r186, 1013904242;
	shr.u32 	%r190, %r186, 5;
	add.s32 	%r191, %r190, -939442524;
	xor.b32  	%r192, %r188, %r189;
	xor.b32  	%r193, %r192, %r191;
	add.s32 	%r194, %r193, %r179;
	shl.b32 	%r195, %r194, 4;
	add.s32 	%r196, %r195, -1383041155;
	add.s32 	%r197, %r194, 1013904242;
	xor.b32  	%r198, %r196, %r197;
	shr.u32 	%r199, %r194, 5;
	add.s32 	%r200, %r199, 2123724318;
	xor.b32  	%r201, %r198, %r200;
	add.s32 	%r202, %r201, %r186;
	shl.b32 	%r203, %r202, 4;
	add.s32 	%r204, %r203, -1556008596;
	add.s32 	%r205, %r202, -626627285;
	shr.u32 	%r206, %r202, 5;
	add.s32 	%r207, %r206, -939442524;
	xor.b32  	%r208, %r204, %r205;
	xor.b32  	%r209, %r208, %r207;
	add.s32 	%r210, %r209, %r194;
	shl.b32 	%r211, %r210, 4;
	add.s32 	%r212, %r211, -1383041155;
	add.s32 	%r213, %r210, -626627285;
	xor.b32  	%r214, %r212, %r213;
	shr.u32 	%r215, %r210, 5;
	add.s32 	%r216, %r215, 2123724318;
	xor.b32  	%r217, %r214, %r216;
	add.s32 	%r218, %r217, %r202;
	shl.b32 	%r219, %r218, 4;
	add.s32 	%r220, %r219, -1556008596;
	add.s32 	%r221, %r218, 2027808484;
	shr.u32 	%r222, %r218, 5;
	add.s32 	%r223, %r222, -939442524;
	xor.b32  	%r224, %r220, %r221;
	xor.b32  	%r225, %r224, %r223;
	add.s32 	%r226, %r225, %r210;
	shl.b32 	%r227, %r226, 4;
	add.s32 	%r228, %r227, -1383041155;
	add.s32 	%r229, %r226, 2027808484;
	xor.b32  	%r230, %r228, %r229;
	shr.u32 	%r231, %r226, 5;
	add.s32 	%r232, %r231, 2123724318;
	xor.b32  	%r233, %r230, %r232;
	add.s32 	%r234, %r233, %r218;
	shl.b32 	%r235, %r234, 4;
	add.s32 	%r236, %r235, -1556008596;
	add.s32 	%r237, %r234, 387276957;
	shr.u32 	%r238, %r234, 5;
	add.s32 	%r239, %r238, -939442524;
	xor.b32  	%r240, %r236, %r237;
	xor.b32  	%r241, %r240, %r239;
	add.s32 	%r242, %r241, %r226;
	shl.b32 	%r243, %r242, 4;
	add.s32 	%r244, %r243, -1383041155;
	add.s32 	%r245, %r242, 387276957;
	xor.b32  	%r246, %r244, %r245;
	shr.u32 	%r247, %r242, 5;
	add.s32 	%r248, %r247, 2123724318;
	xor.b32  	%r249, %r246, %r248;
	add.s32 	%r250, %r249, %r234;
	shl.b32 	%r251, %r250, 4;
	add.s32 	%r252, %r251, -1556008596;
	add.s32 	%r253, %r250, -1253254570;
	shr.u32 	%r254, %r250, 5;
	add.s32 	%r255, %r254, -939442524;
	xor.b32  	%r256, %r252, %r253;
	xor.b32  	%r257, %r256, %r255;
	add.s32 	%r258, %r257, %r242;
	shl.b32 	%r259, %r258, 4;
	add.s32 	%r260, %r259, -1383041155;
	add.s32 	%r261, %r258, -1253254570;
	xor.b32  	%r262, %r260, %r261;
	shr.u32 	%r263, %r258, 5;
	add.s32 	%r264, %r263, 2123724318;
	xor.b32  	%r265, %r262, %r264;
	add.s32 	%r266, %r265, %r250;
	shl.b32 	%r267, %r266, 4;
	add.s32 	%r268, %r267, -1556008596;
	add.s32 	%r269, %r266, 1401181199;
	shr.u32 	%r270, %r266, 5;
	add.s32 	%r271, %r270, -939442524;
	xor.b32  	%r272, %r268, %r269;
	xor.b32  	%r273, %r272, %r271;
	add.s32 	%r274, %r273, %r258;
	shl.b32 	%r275, %r274, 4;
	add.s32 	%r276, %r275, -1383041155;
	add.s32 	%r277, %r274, 1401181199;
	xor.b32  	%r278, %r276, %r277;
	shr.u32 	%r279, %r274, 5;
	add.s32 	%r280, %r279, 2123724318;
	xor.b32  	%r281, %r278, %r280;
	add.s32 	%r282, %r281, %r266;
	shl.b32 	%r283, %r282, 4;
	add.s32 	%r284, %r283, -1556008596;
	add.s32 	%r285, %r282, -239350328;
	shr.u32 	%r286, %r282, 5;
	add.s32 	%r287, %r286, -939442524;
	xor.b32  	%r288, %r284, %r285;
	xor.b32  	%r289, %r288, %r287;
	add.s32 	%r290, %r289, %r274;
	shl.b32 	%r291, %r290, 4;
	add.s32 	%r292, %r291, -1383041155;
	add.s32 	%r293, %r290, -239350328;
	xor.b32  	%r294, %r292, %r293;
	shr.u32 	%r295, %r290, 5;
	add.s32 	%r296, %r295, 2123724318;
	xor.b32  	%r297, %r294, %r296;
	add.s32 	%r298, %r297, %r282;
	shl.b32 	%r299, %r298, 4;
	add.s32 	%r300, %r299, -1556008596;
	add.s32 	%r301, %r298, -1879881855;
	shr.u32 	%r302, %r298, 5;
	add.s32 	%r303, %r302, -939442524;
	xor.b32  	%r304, %r300, %r301;
	xor.b32  	%r305, %r304, %r303;
	add.s32 	%r306, %r305, %r290;
	shl.b32 	%r307, %r306, 4;
	add.s32 	%r308, %r307, -1383041155;
	add.s32 	%r309, %r306, -1879881855;
	xor.b32  	%r310, %r308, %r309;
	shr.u32 	%r311, %r306, 5;
	add.s32 	%r312, %r311, 2123724318;
	xor.b32  	%r313, %r310, %r312;
	add.s32 	%r314, %r313, %r298;
	shl.b32 	%r315, %r314, 4;
	add.s32 	%r316, %r315, -1556008596;
	add.s32 	%r317, %r314, 774553914;
	shr.u32 	%r318, %r314, 5;
	add.s32 	%r319, %r318, -939442524;
	xor.b32  	%r320, %r316, %r317;
	xor.b32  	%r321, %r320, %r319;
	add.s32 	%r322, %r321, %r306;
	shl.b32 	%r323, %r322, 4;
	add.s32 	%r324, %r323, -1383041155;
	add.s32 	%r325, %r322, 774553914;
	xor.b32  	%r326, %r324, %r325;
	shr.u32 	%r327, %r322, 5;
	add.s32 	%r328, %r327, 2123724318;
	xor.b32  	%r329, %r326, %r328;
	add.s32 	%r330, %r329, %r314;
	shl.b32 	%r331, %r330, 4;
	add.s32 	%r332, %r331, -1556008596;
	add.s32 	%r333, %r330, -865977613;
	shr.u32 	%r334, %r330, 5;
	add.s32 	%r335, %r334, -939442524;
	xor.b32  	%r336, %r332, %r333;
	xor.b32  	%r337, %r336, %r335;
	add.s32 	%r338, %r337, %r322;
	shl.b32 	%r339, %r338, 4;
	add.s32 	%r340, %r339, -1383041155;
	add.s32 	%r341, %r338, -865977613;
	xor.b32  	%r342, %r340, %r341;
	shr.u32 	%r343, %r338, 5;
	add.s32 	%r344, %r343, 2123724318;
	xor.b32  	%r345, %r342, %r344;
	add.s32 	%r346, %r345, %r330;
	shl.b32 	%r347, %r346, 4;
	add.s32 	%r348, %r347, -1556008596;
	add.s32 	%r349, %r346, 1788458156;
	shr.u32 	%r350, %r346, 5;
	add.s32 	%r351, %r350, -939442524;
	xor.b32  	%r352, %r348, %r349;
	xor.b32  	%r353, %r352, %r351;
	add.s32 	%r354, %r353, %r338;
	shl.b32 	%r355, %r354, 4;
	add.s32 	%r356, %r355, -1383041155;
	add.s32 	%r357, %r354, 1788458156;
	xor.b32  	%r358, %r356, %r357;
	shr.u32 	%r359, %r354, 5;
	add.s32 	%r360, %r359, 2123724318;
	xor.b32  	%r361, %r358, %r360;
	add.s32 	%r362, %r361, %r346;
	shl.b32 	%r363, %r362, 4;
	add.s32 	%r364, %r363, -1556008596;
	add.s32 	%r365, %r362, 147926629;
	shr.u32 	%r366, %r362, 5;
	add.s32 	%r367, %r366, -939442524;
	xor.b32  	%r368, %r364, %r365;
	xor.b32  	%r369, %r368, %r367;
	add.s32 	%r370, %r369, %r354;
	shl.b32 	%r371, %r370, 4;
	add.s32 	%r372, %r371, -1383041155;
	add.s32 	%r373, %r370, 147926629;
	xor.b32  	%r374, %r372, %r373;
	shr.u32 	%r375, %r370, 5;
	add.s32 	%r376, %r375, 2123724318;
	xor.b32  	%r377, %r374, %r376;
	add.s32 	%r378, %r377, %r362;
	shl.b32 	%r379, %r378, 4;
	add.s32 	%r380, %r379, -1556008596;
	add.s32 	%r381, %r378, -1492604898;
	shr.u32 	%r382, %r378, 5;
	add.s32 	%r383, %r382, -939442524;
	xor.b32  	%r384, %r380, %r381;
	xor.b32  	%r385, %r384, %r383;
	add.s32 	%r386, %r385, %r370;
	shl.b32 	%r387, %r386, 4;
	add.s32 	%r388, %r387, -1383041155;
	add.s32 	%r389, %r386, -1492604898;
	xor.b32  	%r390, %r388, %r389;
	shr.u32 	%r391, %r386, 5;
	add.s32 	%r392, %r391, 2123724318;
	xor.b32  	%r393, %r390, %r392;
	add.s32 	%r394, %r393, %r378;
	shl.b32 	%r395, %r394, 4;
	add.s32 	%r396, %r395, -1556008596;
	add.s32 	%r397, %r394, 1161830871;
	shr.u32 	%r398, %r394, 5;
	add.s32 	%r399, %r398, -939442524;
	xor.b32  	%r400, %r396, %r397;
	xor.b32  	%r401, %r400, %r399;
	add.s32 	%r402, %r401, %r386;
	shl.b32 	%r403, %r402, 4;
	add.s32 	%r404, %r403, -1383041155;
	add.s32 	%r405, %r402, 1161830871;
	xor.b32  	%r406, %r404, %r405;
	shr.u32 	%r407, %r402, 5;
	add.s32 	%r408, %r407, 2123724318;
	xor.b32  	%r409, %r406, %r408;
	add.s32 	%r410, %r409, %r394;
	shl.b32 	%r411, %r410, 4;
	add.s32 	%r412, %r411, -1556008596;
	add.s32 	%r413, %r410, -478700656;
	shr.u32 	%r414, %r410, 5;
	add.s32 	%r415, %r414, -939442524;
	xor.b32  	%r416, %r412, %r413;
	xor.b32  	%r417, %r416, %r415;
	add.s32 	%r418, %r417, %r402;
	not.b32 	%r419, %r174;
	add.s32 	%r420, %r177, %r419;
	cvt.rn.f32.u32 	%f223, %r173;
	mad.lo.s32 	%r421, %r418, 1664525, 1013904223;
	shr.u32 	%r422, %r421, 9;
	or.b32  	%r423, %r422, 1065353216;
	mov.b32 	%f224, %r423;
	add.f32 	%f225, %f224, 0fBF800000;
	add.f32 	%f226, %f225, %f223;
	cvt.rn.f32.u32 	%f227, %r176;
	div.rn.f32 	%f228, %f226, %f227;
	fma.rn.f32 	%f1, %f228, 0f40000000, 0fBF800000;
	cvt.rn.f32.u32 	%f229, %r420;
	mad.lo.s32 	%r2, %r421, 1664525, 1013904223;
	shr.u32 	%r424, %r2, 9;
	or.b32  	%r425, %r424, 1065353216;
	mov.b32 	%f230, %r425;
	add.f32 	%f231, %f230, 0fBF800000;
	add.f32 	%f232, %f231, %f229;
	cvt.rn.f32.u32 	%f233, %r177;
	div.rn.f32 	%f234, %f232, %f233;
	fma.rn.f32 	%f2, %f234, 0f40000000, 0fBF800000;
	ld.const.u32 	%r426, [global+160];
	setp.eq.s32 	%p3, %r426, 1;
	@%p3 bra 	$L__BB0_194;
	bra.uni 	$L__BB0_1;

$L__BB0_194:
	mul.f32 	%f156, %f1, 0f40490FDB;
	mul.f32 	%f157, %f2, 0f3FC90FDB;
	mul.f32 	%f454, %f156, 0f3F22F983;
	cvt.rni.s32.f32 	%r914, %f454;
	cvt.rn.f32.s32 	%f455, %r914;
	mov.f32 	%f456, 0fBFC90FDA;
	fma.rn.f32 	%f457, %f455, %f456, %f156;
	mov.f32 	%f458, 0fB3A22168;
	fma.rn.f32 	%f459, %f455, %f458, %f457;
	mov.f32 	%f460, 0fA7C234C5;
	fma.rn.f32 	%f587, %f455, %f460, %f459;
	abs.f32 	%f159, %f156;
	setp.leu.f32 	%p166, %f159, 0f47CE4780;
	mov.u32 	%r910, %r914;
	mov.f32 	%f584, %f587;
	@%p166 bra 	$L__BB0_202;

	setp.eq.f32 	%p167, %f159, 0f7F800000;
	@%p167 bra 	$L__BB0_201;
	bra.uni 	$L__BB0_196;

$L__BB0_201:
	mov.f32 	%f463, 0f00000000;
	mul.rn.f32 	%f584, %f156, %f463;
	mov.u32 	%r910, 0;
	bra.uni 	$L__BB0_202;

$L__BB0_1:
	ld.const.v4.f32 	{%f596, %f597, %f598, %f238}, [global+80];
	ld.const.v4.f32 	{%f240, %f241, %f242, %f243}, [global+96];
	mul.f32 	%f245, %f1, %f243;
	ld.const.v4.f32 	{%f246, %f247, %f248, %f249}, [global+112];
	mul.f32 	%f250, %f2, %f246;
	mul.f32 	%f251, %f2, %f247;
	mul.f32 	%f252, %f2, %f248;
	fma.rn.f32 	%f253, %f240, %f245, %f250;
	fma.rn.f32 	%f254, %f245, %f241, %f251;
	fma.rn.f32 	%f255, %f245, %f242, %f252;
	ld.const.v4.f32 	{%f256, %f257, %f258, %f259}, [global+128];
	fma.rn.f32 	%f260, %f253, %f238, %f256;
	fma.rn.f32 	%f261, %f254, %f238, %f257;
	fma.rn.f32 	%f262, %f238, %f255, %f258;
	mul.f32 	%f263, %f261, %f261;
	fma.rn.f32 	%f264, %f260, %f260, %f263;
	fma.rn.f32 	%f265, %f262, %f262, %f264;
	sqrt.rn.f32 	%f266, %f265;
	div.rn.f32 	%f600, %f260, %f266;
	div.rn.f32 	%f601, %f261, %f266;
	div.rn.f32 	%f602, %f262, %f266;
	setp.leu.f32 	%p4, %f259, 0f00000000;
	@%p4 bra 	$L__BB0_193;

	ld.const.u32 	%rd3, [global+372];
	setp.eq.s64 	%p5, %rd3, 4294967295;
	@%p5 bra 	$L__BB0_162;

	ld.const.u64 	%rd4, [global+248];
	setp.ne.s64 	%p6, %rd4, 0;
	cvta.to.local.u64 	%rd5, %rd80;
	@%p6 bra 	$L__BB0_5;

	mov.u64 	%rd82, $str$1;
	cvta.global.u64 	%rd83, %rd82;
	st.local.u64 	[%rd5], %rd83;
	mov.u64 	%rd84, $str$2;
	cvta.global.u64 	%rd85, %rd84;
	st.local.u64 	[%rd5+8], %rd85;
	mov.u32 	%r427, 61;
	st.local.u32 	[%rd5+16], %r427;
	mov.u64 	%rd86, $str;
	cvta.global.u64 	%rd87, %rd86;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r428, [retval0+0];
	} // callseq 0

$L__BB0_5:
	ld.const.u64 	%rd6, [global+240];
	setp.ne.s64 	%p7, %rd6, 0;
	@%p7 bra 	$L__BB0_7;

	mov.u64 	%rd89, $str$3;
	cvta.global.u64 	%rd90, %rd89;
	st.local.u64 	[%rd5], %rd90;
	mov.u64 	%rd91, $str$2;
	cvta.global.u64 	%rd92, %rd91;
	st.local.u64 	[%rd5+8], %rd92;
	mov.u32 	%r429, 62;
	st.local.u32 	[%rd5+16], %r429;
	mov.u64 	%rd93, $str;
	cvta.global.u64 	%rd94, %rd93;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd94;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r430, [retval0+0];
	} // callseq 1

$L__BB0_7:
	setp.gt.u64 	%p8, %rd4, %rd3;
	@%p8 bra 	$L__BB0_9;

	mov.u64 	%rd96, $str$4;
	cvta.global.u64 	%rd97, %rd96;
	st.local.u64 	[%rd5], %rd97;
	mov.u64 	%rd98, $str$2;
	cvta.global.u64 	%rd99, %rd98;
	st.local.u64 	[%rd5+8], %rd99;
	mov.u32 	%r431, 63;
	st.local.u32 	[%rd5+16], %r431;
	mov.u64 	%rd100, $str;
	cvta.global.u64 	%rd101, %rd100;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd101;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r432, [retval0+0];
	} // callseq 2

$L__BB0_9:
	mad.lo.s32 	%r434, %r2, 1664525, 1013904223;
	shr.u32 	%r435, %r434, 9;
	or.b32  	%r436, %r435, 1065353216;
	mov.b32 	%f267, %r436;
	add.f32 	%f19, %f267, 0fBF800000;
	mad.lo.s32 	%r437, %r434, 1664525, 1013904223;
	shr.u32 	%r438, %r437, 9;
	or.b32  	%r439, %r438, 1065353216;
	mov.b32 	%f268, %r439;
	add.f32 	%f20, %f268, 0fBF800000;
	cvta.to.global.u64 	%rd103, %rd6;
	mul.lo.s64 	%rd104, %rd3, 80;
	add.s64 	%rd105, %rd103, %rd104;
	add.s64 	%rd7, %rd105, 24;
	ld.global.u64 	%rd456, [%rd105+24];
	cvt.u32.u64 	%r881, %rd456;
	add.u64 	%rd107, %SP, 48;
	add.u64 	%rd10, %SPL, 48;
	mov.u32 	%r880, 0;
	bra.uni 	$L__BB0_10;

$L__BB0_161:
	ld.global.u64 	%rd456, [%rd7];

$L__BB0_10:
	sub.s32 	%r440, %r881, %r880;
	shr.u32 	%r441, %r440, 1;
	add.s32 	%r442, %r441, %r880;
	cvt.u64.u32 	%rd12, %r442;
	setp.ne.s64 	%p9, %rd456, 0;
	@%p9 bra 	$L__BB0_12;

	mov.u64 	%rd108, $str$1;
	cvta.global.u64 	%rd109, %rd108;
	st.local.u64 	[%rd5], %rd109;
	mov.u64 	%rd110, $str$2;
	cvta.global.u64 	%rd111, %rd110;
	st.local.u64 	[%rd5+8], %rd111;
	mov.u32 	%r443, 61;
	st.local.u32 	[%rd5+16], %r443;
	mov.u64 	%rd112, $str;
	cvta.global.u64 	%rd113, %rd112;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd113;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r444, [retval0+0];
	} // callseq 3

$L__BB0_12:
	ld.global.u64 	%rd115, [%rd7+-8];
	setp.ne.s64 	%p10, %rd115, 0;
	@%p10 bra 	$L__BB0_14;

	mov.u64 	%rd116, $str$3;
	cvta.global.u64 	%rd117, %rd116;
	st.local.u64 	[%rd5], %rd117;
	mov.u64 	%rd118, $str$2;
	cvta.global.u64 	%rd119, %rd118;
	st.local.u64 	[%rd5+8], %rd119;
	mov.u32 	%r445, 62;
	st.local.u32 	[%rd5+16], %r445;
	mov.u64 	%rd120, $str;
	cvta.global.u64 	%rd121, %rd120;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r446, [retval0+0];
	} // callseq 4

$L__BB0_14:
	ld.global.u64 	%rd123, [%rd7];
	setp.gt.u64 	%p11, %rd123, %rd12;
	@%p11 bra 	$L__BB0_16;

	mov.u64 	%rd124, $str$4;
	cvta.global.u64 	%rd125, %rd124;
	st.local.u64 	[%rd5], %rd125;
	mov.u64 	%rd126, $str$2;
	cvta.global.u64 	%rd127, %rd126;
	st.local.u64 	[%rd5+8], %rd127;
	mov.u32 	%r447, 63;
	st.local.u32 	[%rd5+16], %r447;
	mov.u64 	%rd128, $str;
	cvta.global.u64 	%rd129, %rd128;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd129;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r448, [retval0+0];
	} // callseq 5

$L__BB0_16:
	cvt.u32.u64 	%r449, %rd12;
	ld.global.u64 	%rd131, [%rd7+-8];
	mul.lo.s64 	%rd132, %rd12, 12;
	add.s64 	%rd133, %rd131, %rd132;
	ld.f32 	%f269, [%rd133+8];
	setp.ge.f32 	%p12, %f269, %f20;
	selp.b32 	%r880, %r880, %r449, %p12;
	selp.b32 	%r881, %r449, %r881, %p12;
	sub.s32 	%r450, %r881, %r880;
	setp.gt.u32 	%p13, %r450, 1;
	@%p13 bra 	$L__BB0_161;

	cvt.u64.u32 	%rd13, %r880;
	ld.global.u64 	%rd134, [%rd7];
	setp.ne.s64 	%p14, %rd134, 0;
	@%p14 bra 	$L__BB0_19;

	mov.u64 	%rd135, $str$1;
	cvta.global.u64 	%rd136, %rd135;
	st.local.u64 	[%rd5], %rd136;
	mov.u64 	%rd137, $str$2;
	cvta.global.u64 	%rd138, %rd137;
	st.local.u64 	[%rd5+8], %rd138;
	mov.u32 	%r451, 61;
	st.local.u32 	[%rd5+16], %r451;
	mov.u64 	%rd139, $str;
	cvta.global.u64 	%rd140, %rd139;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd140;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r452, [retval0+0];
	} // callseq 6

$L__BB0_19:
	ld.global.u64 	%rd142, [%rd7+-8];
	setp.ne.s64 	%p15, %rd142, 0;
	@%p15 bra 	$L__BB0_21;

	mov.u64 	%rd143, $str$3;
	cvta.global.u64 	%rd144, %rd143;
	st.local.u64 	[%rd5], %rd144;
	mov.u64 	%rd145, $str$2;
	cvta.global.u64 	%rd146, %rd145;
	st.local.u64 	[%rd5+8], %rd146;
	mov.u32 	%r453, 62;
	st.local.u32 	[%rd5+16], %r453;
	mov.u64 	%rd147, $str;
	cvta.global.u64 	%rd148, %rd147;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd148;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r454, [retval0+0];
	} // callseq 7

$L__BB0_21:
	ld.global.u64 	%rd150, [%rd7];
	setp.gt.u64 	%p16, %rd150, %rd13;
	@%p16 bra 	$L__BB0_23;

	mov.u64 	%rd151, $str$4;
	cvta.global.u64 	%rd152, %rd151;
	st.local.u64 	[%rd5], %rd152;
	mov.u64 	%rd153, $str$2;
	cvta.global.u64 	%rd154, %rd153;
	st.local.u64 	[%rd5+8], %rd154;
	mov.u32 	%r455, 63;
	st.local.u32 	[%rd5+16], %r455;
	mov.u64 	%rd155, $str;
	cvta.global.u64 	%rd156, %rd155;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd156;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r456, [retval0+0];
	} // callseq 8

$L__BB0_23:
	ld.global.u64 	%rd158, [%rd7+-16];
	shl.b64 	%rd159, %rd13, 5;
	add.s64 	%rd160, %rd158, %rd159;
	add.s64 	%rd14, %rd160, 8;
	ld.u64 	%rd457, [%rd160+8];
	cvt.u32.u64 	%r883, %rd457;
	mov.u32 	%r882, 0;
	bra.uni 	$L__BB0_24;

$L__BB0_160:
	ld.u64 	%rd457, [%rd14];

$L__BB0_24:
	sub.s32 	%r458, %r883, %r882;
	shr.u32 	%r459, %r458, 1;
	add.s32 	%r460, %r459, %r882;
	cvt.u64.u32 	%rd17, %r460;
	setp.ne.s64 	%p17, %rd457, 0;
	@%p17 bra 	$L__BB0_26;

	mov.u64 	%rd161, $str$1;
	cvta.global.u64 	%rd162, %rd161;
	st.local.u64 	[%rd5], %rd162;
	mov.u64 	%rd163, $str$2;
	cvta.global.u64 	%rd164, %rd163;
	st.local.u64 	[%rd5+8], %rd164;
	mov.u32 	%r461, 61;
	st.local.u32 	[%rd5+16], %r461;
	mov.u64 	%rd165, $str;
	cvta.global.u64 	%rd166, %rd165;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd166;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r462, [retval0+0];
	} // callseq 9

$L__BB0_26:
	ld.u64 	%rd168, [%rd14+-8];
	setp.ne.s64 	%p18, %rd168, 0;
	@%p18 bra 	$L__BB0_28;

	mov.u64 	%rd169, $str$3;
	cvta.global.u64 	%rd170, %rd169;
	st.local.u64 	[%rd5], %rd170;
	mov.u64 	%rd171, $str$2;
	cvta.global.u64 	%rd172, %rd171;
	st.local.u64 	[%rd5+8], %rd172;
	mov.u32 	%r463, 62;
	st.local.u32 	[%rd5+16], %r463;
	mov.u64 	%rd173, $str;
	cvta.global.u64 	%rd174, %rd173;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd174;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r464, [retval0+0];
	} // callseq 10

$L__BB0_28:
	ld.u64 	%rd176, [%rd14];
	setp.gt.u64 	%p19, %rd176, %rd17;
	@%p19 bra 	$L__BB0_30;

	mov.u64 	%rd177, $str$4;
	cvta.global.u64 	%rd178, %rd177;
	st.local.u64 	[%rd5], %rd178;
	mov.u64 	%rd179, $str$2;
	cvta.global.u64 	%rd180, %rd179;
	st.local.u64 	[%rd5+8], %rd180;
	mov.u32 	%r465, 63;
	st.local.u32 	[%rd5+16], %r465;
	mov.u64 	%rd181, $str;
	cvta.global.u64 	%rd182, %rd181;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd182;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r466, [retval0+0];
	} // callseq 11

$L__BB0_30:
	cvt.u32.u64 	%r467, %rd17;
	ld.u64 	%rd184, [%rd14+-8];
	mul.lo.s64 	%rd185, %rd17, 12;
	add.s64 	%rd186, %rd184, %rd185;
	ld.f32 	%f270, [%rd186+8];
	setp.ge.f32 	%p20, %f270, %f19;
	selp.b32 	%r882, %r882, %r467, %p20;
	selp.b32 	%r883, %r467, %r883, %p20;
	sub.s32 	%r468, %r883, %r882;
	setp.gt.u32 	%p21, %r468, 1;
	@%p21 bra 	$L__BB0_160;

	cvt.u64.u32 	%rd18, %r882;
	ld.u64 	%rd187, [%rd14];
	setp.ne.s64 	%p22, %rd187, 0;
	@%p22 bra 	$L__BB0_33;

	mov.u64 	%rd188, $str$1;
	cvta.global.u64 	%rd189, %rd188;
	st.local.u64 	[%rd5], %rd189;
	mov.u64 	%rd190, $str$2;
	cvta.global.u64 	%rd191, %rd190;
	st.local.u64 	[%rd5+8], %rd191;
	mov.u32 	%r469, 61;
	st.local.u32 	[%rd5+16], %r469;
	mov.u64 	%rd192, $str;
	cvta.global.u64 	%rd193, %rd192;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd193;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r470, [retval0+0];
	} // callseq 12

$L__BB0_33:
	ld.u64 	%rd195, [%rd14+-8];
	setp.ne.s64 	%p23, %rd195, 0;
	@%p23 bra 	$L__BB0_35;

	mov.u64 	%rd196, $str$3;
	cvta.global.u64 	%rd197, %rd196;
	st.local.u64 	[%rd5], %rd197;
	mov.u64 	%rd198, $str$2;
	cvta.global.u64 	%rd199, %rd198;
	st.local.u64 	[%rd5+8], %rd199;
	mov.u32 	%r471, 62;
	st.local.u32 	[%rd5+16], %r471;
	mov.u64 	%rd200, $str;
	cvta.global.u64 	%rd201, %rd200;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd201;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r472, [retval0+0];
	} // callseq 13

$L__BB0_35:
	ld.u64 	%rd203, [%rd14];
	setp.gt.u64 	%p24, %rd203, %rd18;
	@%p24 bra 	$L__BB0_37;

	mov.u64 	%rd204, $str$4;
	cvta.global.u64 	%rd205, %rd204;
	st.local.u64 	[%rd5], %rd205;
	mov.u64 	%rd206, $str$2;
	cvta.global.u64 	%rd207, %rd206;
	st.local.u64 	[%rd5+8], %rd207;
	mov.u32 	%r473, 63;
	st.local.u32 	[%rd5+16], %r473;
	mov.u64 	%rd208, $str;
	cvta.global.u64 	%rd209, %rd208;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd209;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r474, [retval0+0];
	} // callseq 14

$L__BB0_37:
	ld.u64 	%rd211, [%rd14];
	setp.ne.s64 	%p25, %rd211, 0;
	@%p25 bra 	$L__BB0_39;

	mov.u64 	%rd212, $str$1;
	cvta.global.u64 	%rd213, %rd212;
	st.local.u64 	[%rd5], %rd213;
	mov.u64 	%rd214, $str$2;
	cvta.global.u64 	%rd215, %rd214;
	st.local.u64 	[%rd5+8], %rd215;
	mov.u32 	%r475, 61;
	st.local.u32 	[%rd5+16], %r475;
	mov.u64 	%rd216, $str;
	cvta.global.u64 	%rd217, %rd216;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd217;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r476, [retval0+0];
	} // callseq 15

$L__BB0_39:
	ld.u64 	%rd219, [%rd14+-8];
	setp.ne.s64 	%p26, %rd219, 0;
	@%p26 bra 	$L__BB0_41;

	mov.u64 	%rd220, $str$3;
	cvta.global.u64 	%rd221, %rd220;
	st.local.u64 	[%rd5], %rd221;
	mov.u64 	%rd222, $str$2;
	cvta.global.u64 	%rd223, %rd222;
	st.local.u64 	[%rd5+8], %rd223;
	mov.u32 	%r477, 62;
	st.local.u32 	[%rd5+16], %r477;
	mov.u64 	%rd224, $str;
	cvta.global.u64 	%rd225, %rd224;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd225;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r478, [retval0+0];
	} // callseq 16

$L__BB0_41:
	ld.u64 	%rd227, [%rd14];
	setp.gt.u64 	%p27, %rd227, %rd18;
	@%p27 bra 	$L__BB0_43;

	mov.u64 	%rd228, $str$4;
	cvta.global.u64 	%rd229, %rd228;
	st.local.u64 	[%rd5], %rd229;
	mov.u64 	%rd230, $str$2;
	cvta.global.u64 	%rd231, %rd230;
	st.local.u64 	[%rd5+8], %rd231;
	mov.u32 	%r479, 63;
	st.local.u32 	[%rd5+16], %r479;
	mov.u64 	%rd232, $str;
	cvta.global.u64 	%rd233, %rd232;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd233;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r480, [retval0+0];
	} // callseq 17

$L__BB0_43:
	ld.u64 	%rd235, [%rd14+-8];
	mul.lo.s64 	%rd236, %rd18, 12;
	add.s64 	%rd237, %rd235, %rd236;
	ld.f32 	%f21, [%rd237+8];
	ld.u64 	%rd238, [%rd14];
	add.s64 	%rd239, %rd18, 1;
	min.u64 	%rd19, %rd239, %rd238;
	setp.ne.s64 	%p28, %rd238, 0;
	@%p28 bra 	$L__BB0_45;

	mov.u64 	%rd240, $str$1;
	cvta.global.u64 	%rd241, %rd240;
	st.local.u64 	[%rd5], %rd241;
	mov.u64 	%rd242, $str$2;
	cvta.global.u64 	%rd243, %rd242;
	st.local.u64 	[%rd5+8], %rd243;
	mov.u32 	%r481, 61;
	st.local.u32 	[%rd5+16], %r481;
	mov.u64 	%rd244, $str;
	cvta.global.u64 	%rd245, %rd244;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd245;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r482, [retval0+0];
	} // callseq 18

$L__BB0_45:
	ld.u64 	%rd247, [%rd14+-8];
	setp.ne.s64 	%p29, %rd247, 0;
	@%p29 bra 	$L__BB0_47;

	mov.u64 	%rd248, $str$3;
	cvta.global.u64 	%rd249, %rd248;
	st.local.u64 	[%rd5], %rd249;
	mov.u64 	%rd250, $str$2;
	cvta.global.u64 	%rd251, %rd250;
	st.local.u64 	[%rd5+8], %rd251;
	mov.u32 	%r483, 62;
	st.local.u32 	[%rd5+16], %r483;
	mov.u64 	%rd252, $str;
	cvta.global.u64 	%rd253, %rd252;
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd253;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r484, [retval0+0];
	} // callseq 19

$L__BB0_47:
	ld.u64 	%rd255, [%rd14];
	setp.gt.u64 	%p30, %rd255, %rd19;
	@%p30 bra 	$L__BB0_49;

	mov.u64 	%rd256, $str$4;
	cvta.global.u64 	%rd257, %rd256;
	st.local.u64 	[%rd5], %rd257;
	mov.u64 	%rd258, $str$2;
	cvta.global.u64 	%rd259, %rd258;
	st.local.u64 	[%rd5+8], %rd259;
	mov.u32 	%r485, 63;
	st.local.u32 	[%rd5+16], %r485;
	mov.u64 	%rd260, $str;
	cvta.global.u64 	%rd261, %rd260;
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd261;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r486, [retval0+0];
	} // callseq 20

$L__BB0_49:
	ld.u64 	%rd263, [%rd14+-8];
	mul.lo.s64 	%rd264, %rd19, 12;
	add.s64 	%rd265, %rd263, %rd264;
	sub.f32 	%f556, %f19, %f21;
	ld.f32 	%f271, [%rd265+8];
	sub.f32 	%f23, %f271, %f21;
	setp.leu.f32 	%p31, %f23, 0f00000000;
	@%p31 bra 	$L__BB0_51;

	div.rn.f32 	%f556, %f556, %f23;

$L__BB0_51:
	ld.global.u64 	%rd266, [%rd7];
	setp.ne.s64 	%p32, %rd266, 0;
	@%p32 bra 	$L__BB0_53;

	mov.u64 	%rd267, $str$1;
	cvta.global.u64 	%rd268, %rd267;
	st.local.u64 	[%rd5], %rd268;
	mov.u64 	%rd269, $str$2;
	cvta.global.u64 	%rd270, %rd269;
	st.local.u64 	[%rd5+8], %rd270;
	mov.u32 	%r487, 61;
	st.local.u32 	[%rd5+16], %r487;
	mov.u64 	%rd271, $str;
	cvta.global.u64 	%rd272, %rd271;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd272;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r488, [retval0+0];
	} // callseq 21

$L__BB0_53:
	ld.global.u64 	%rd274, [%rd7+-8];
	setp.ne.s64 	%p33, %rd274, 0;
	@%p33 bra 	$L__BB0_55;

	mov.u64 	%rd275, $str$3;
	cvta.global.u64 	%rd276, %rd275;
	st.local.u64 	[%rd5], %rd276;
	mov.u64 	%rd277, $str$2;
	cvta.global.u64 	%rd278, %rd277;
	st.local.u64 	[%rd5+8], %rd278;
	mov.u32 	%r489, 62;
	st.local.u32 	[%rd5+16], %r489;
	mov.u64 	%rd279, $str;
	cvta.global.u64 	%rd280, %rd279;
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd280;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r490, [retval0+0];
	} // callseq 22

$L__BB0_55:
	ld.global.u64 	%rd282, [%rd7];
	setp.gt.u64 	%p34, %rd282, %rd13;
	@%p34 bra 	$L__BB0_57;

	mov.u64 	%rd283, $str$4;
	cvta.global.u64 	%rd284, %rd283;
	st.local.u64 	[%rd5], %rd284;
	mov.u64 	%rd285, $str$2;
	cvta.global.u64 	%rd286, %rd285;
	st.local.u64 	[%rd5+8], %rd286;
	mov.u32 	%r491, 63;
	st.local.u32 	[%rd5+16], %r491;
	mov.u64 	%rd287, $str;
	cvta.global.u64 	%rd288, %rd287;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd288;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r492, [retval0+0];
	} // callseq 23

$L__BB0_57:
	ld.global.u64 	%rd290, [%rd7+-8];
	mul.lo.s64 	%rd291, %rd13, 12;
	add.s64 	%rd292, %rd290, %rd291;
	ld.f32 	%f26, [%rd292+8];
	ld.global.u64 	%rd293, [%rd7];
	add.s64 	%rd294, %rd13, 1;
	min.u64 	%rd20, %rd294, %rd293;
	setp.ne.s64 	%p35, %rd293, 0;
	@%p35 bra 	$L__BB0_59;

	mov.u64 	%rd295, $str$1;
	cvta.global.u64 	%rd296, %rd295;
	st.local.u64 	[%rd5], %rd296;
	mov.u64 	%rd297, $str$2;
	cvta.global.u64 	%rd298, %rd297;
	st.local.u64 	[%rd5+8], %rd298;
	mov.u32 	%r493, 61;
	st.local.u32 	[%rd5+16], %r493;
	mov.u64 	%rd299, $str;
	cvta.global.u64 	%rd300, %rd299;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd300;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r494, [retval0+0];
	} // callseq 24

$L__BB0_59:
	ld.global.u64 	%rd302, [%rd7+-8];
	setp.ne.s64 	%p36, %rd302, 0;
	@%p36 bra 	$L__BB0_61;

	mov.u64 	%rd303, $str$3;
	cvta.global.u64 	%rd304, %rd303;
	st.local.u64 	[%rd5], %rd304;
	mov.u64 	%rd305, $str$2;
	cvta.global.u64 	%rd306, %rd305;
	st.local.u64 	[%rd5+8], %rd306;
	mov.u32 	%r495, 62;
	st.local.u32 	[%rd5+16], %r495;
	mov.u64 	%rd307, $str;
	cvta.global.u64 	%rd308, %rd307;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd308;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r496, [retval0+0];
	} // callseq 25

$L__BB0_61:
	ld.global.u64 	%rd310, [%rd7];
	setp.gt.u64 	%p37, %rd310, %rd20;
	@%p37 bra 	$L__BB0_63;

	mov.u64 	%rd311, $str$4;
	cvta.global.u64 	%rd312, %rd311;
	st.local.u64 	[%rd5], %rd312;
	mov.u64 	%rd313, $str$2;
	cvta.global.u64 	%rd314, %rd313;
	st.local.u64 	[%rd5+8], %rd314;
	mov.u32 	%r497, 63;
	st.local.u32 	[%rd5+16], %r497;
	mov.u64 	%rd315, $str;
	cvta.global.u64 	%rd316, %rd315;
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd316;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r498, [retval0+0];
	} // callseq 26

$L__BB0_63:
	ld.global.u64 	%rd318, [%rd7+-8];
	mul.lo.s64 	%rd319, %rd20, 12;
	add.s64 	%rd320, %rd318, %rd319;
	sub.f32 	%f557, %f20, %f26;
	ld.f32 	%f272, [%rd320+8];
	sub.f32 	%f28, %f272, %f26;
	setp.leu.f32 	%p38, %f28, 0f00000000;
	@%p38 bra 	$L__BB0_65;

	div.rn.f32 	%f557, %f557, %f28;

$L__BB0_65:
	cvt.rn.f32.u32 	%f273, %r882;
	add.f32 	%f274, %f556, %f273;
	ld.global.v2.f32 	{%f275, %f276}, [%rd7+24];
	div.rn.f32 	%f33, %f274, %f275;
	cvt.rn.f32.u32 	%f277, %r880;
	add.f32 	%f278, %f557, %f277;
	div.rn.f32 	%f34, %f278, %f276;
	mul.f32 	%f559, %f33, %f275;
	mul.f32 	%f563, %f34, %f276;
	ld.global.u32 	%r13, [%rd7+44];
	and.b32  	%r499, %r13, 2;
	setp.eq.s32 	%p39, %r499, 0;
	abs.f32 	%f37, %f275;
	@%p39 bra 	$L__BB0_79;
	bra.uni 	$L__BB0_66;

$L__BB0_79:
	setp.gtu.f32 	%p54, %f37, 0f7F800000;
	@%p54 bra 	$L__BB0_82;
	bra.uni 	$L__BB0_80;

$L__BB0_82:
	add.f32 	%f560, %f275, 0f00000000;
	bra.uni 	$L__BB0_83;

$L__BB0_196:
	mov.b32 	%r101, %f156;
	bfe.u32 	%r659, %r101, 23, 8;
	add.s32 	%r102, %r659, -128;
	shl.b32 	%r660, %r101, 8;
	or.b32  	%r103, %r660, -2147483648;
	shr.u32 	%r104, %r102, 5;
	mov.u64 	%rd475, 0;
	mov.u32 	%r907, 0;
	mov.u64 	%rd473, __cudart_i2opi_f;
	mov.u64 	%rd474, %rd1;

$L__BB0_197:
	.pragma "nounroll";
	ld.global.nc.u32 	%r661, [%rd473];
	mad.wide.u32 	%rd405, %r661, %r103, %rd475;
	shr.u64 	%rd475, %rd405, 32;
	st.local.u32 	[%rd474], %rd405;
	add.s64 	%rd474, %rd474, 4;
	add.s64 	%rd473, %rd473, 4;
	add.s32 	%r907, %r907, 1;
	setp.ne.s32 	%p168, %r907, 6;
	@%p168 bra 	$L__BB0_197;

	add.s64 	%rd455, %rd1, 24;
	st.local.u32 	[%rd455], %rd475;
	mov.u32 	%r662, 4;
	sub.s32 	%r107, %r662, %r104;
	mov.u32 	%r663, 6;
	sub.s32 	%r664, %r663, %r104;
	mul.wide.s32 	%rd406, %r664, 4;
	add.s64 	%rd407, %rd1, %rd406;
	ld.local.u32 	%r908, [%rd407];
	ld.local.u32 	%r909, [%rd407+-4];
	and.b32  	%r110, %r102, 31;
	setp.eq.s32 	%p169, %r110, 0;
	@%p169 bra 	$L__BB0_200;

	mov.u32 	%r665, 32;
	sub.s32 	%r666, %r665, %r110;
	shr.u32 	%r667, %r909, %r666;
	shl.b32 	%r668, %r908, %r110;
	add.s32 	%r908, %r667, %r668;
	mul.wide.s32 	%rd408, %r107, 4;
	add.s64 	%rd409, %rd1, %rd408;
	ld.local.u32 	%r669, [%rd409];
	shr.u32 	%r670, %r669, %r666;
	shl.b32 	%r671, %r909, %r110;
	add.s32 	%r909, %r670, %r671;

$L__BB0_200:
	and.b32  	%r672, %r101, -2147483648;
	shr.u32 	%r673, %r909, 30;
	shl.b32 	%r674, %r908, 2;
	or.b32  	%r675, %r673, %r674;
	shr.u32 	%r676, %r675, 31;
	shr.u32 	%r677, %r908, 30;
	add.s32 	%r678, %r676, %r677;
	neg.s32 	%r679, %r678;
	setp.eq.s32 	%p170, %r672, 0;
	selp.b32 	%r910, %r678, %r679, %p170;
	setp.ne.s32 	%p171, %r676, 0;
	xor.b32  	%r680, %r672, -2147483648;
	selp.b32 	%r681, %r680, %r672, %p171;
	selp.b32 	%r682, -1, 0, %p171;
	xor.b32  	%r683, %r675, %r682;
	shl.b32 	%r684, %r909, 2;
	xor.b32  	%r685, %r684, %r682;
	cvt.u64.u32 	%rd410, %r683;
	cvt.u64.u32 	%rd411, %r685;
	bfi.b64 	%rd412, %rd410, %rd411, 32, 32;
	cvt.rn.f64.s64 	%fd21, %rd412;
	mul.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f461, %fd22;
	setp.eq.s32 	%p172, %r681, 0;
	neg.f32 	%f462, %f461;
	selp.f32 	%f584, %f461, %f462, %p172;

$L__BB0_202:
	add.s32 	%r117, %r910, 1;
	and.b32  	%r118, %r117, 1;
	setp.eq.s32 	%p173, %r118, 0;
	selp.f32 	%f163, %f584, 0f3F800000, %p173;
	mul.rn.f32 	%f164, %f584, %f584;
	mov.f32 	%f585, 0fB94D4153;
	@%p173 bra 	$L__BB0_204;

	mov.f32 	%f465, 0fBAB607ED;
	mov.f32 	%f466, 0f37CBAC00;
	fma.rn.f32 	%f585, %f466, %f164, %f465;

$L__BB0_204:
	selp.f32 	%f467, 0f3C0885E4, 0f3D2AAABB, %p173;
	fma.rn.f32 	%f468, %f585, %f164, %f467;
	selp.f32 	%f469, 0fBE2AAAA8, 0fBEFFFFFF, %p173;
	fma.rn.f32 	%f470, %f468, %f164, %f469;
	mov.f32 	%f471, 0f00000000;
	fma.rn.f32 	%f472, %f164, %f163, %f471;
	fma.rn.f32 	%f586, %f470, %f472, %f163;
	and.b32  	%r687, %r117, 2;
	setp.eq.s32 	%p175, %r687, 0;
	@%p175 bra 	$L__BB0_206;

	mov.f32 	%f474, 0fBF800000;
	fma.rn.f32 	%f586, %f586, %f474, %f471;

$L__BB0_206:
	@%p166 bra 	$L__BB0_214;

	setp.eq.f32 	%p177, %f159, 0f7F800000;
	@%p177 bra 	$L__BB0_213;
	bra.uni 	$L__BB0_208;

$L__BB0_213:
	mul.rn.f32 	%f587, %f156, %f471;
	mov.u32 	%r914, 0;
	bra.uni 	$L__BB0_214;

$L__BB0_162:
	mad.lo.s32 	%r592, %r2, 1664525, 1013904223;
	shr.u32 	%r593, %r592, 9;
	or.b32  	%r594, %r593, 1065353216;
	mov.b32 	%f391, %r594;
	add.f32 	%f392, %f391, 0fBF800000;
	mad.lo.s32 	%r595, %r592, 1664525, 1013904223;
	shr.u32 	%r596, %r595, 9;
	or.b32  	%r597, %r596, 1065353216;
	mov.b32 	%f393, %r597;
	add.f32 	%f394, %f393, 0fBF800000;
	fma.rn.f32 	%f100, %f392, 0f40000000, 0fBF800000;
	fma.rn.f32 	%f566, %f394, 0f40000000, 0fBF800000;
	setp.eq.f32 	%p142, %f100, 0f00000000;
	setp.eq.f32 	%p143, %f566, 0f00000000;
	and.pred  	%p144, %p142, %p143;
	mov.f32 	%f576, 0f00000000;
	mov.f32 	%f577, %f576;
	@%p144 bra 	$L__BB0_192;

	abs.f32 	%f395, %f100;
	abs.f32 	%f396, %f566;
	setp.gt.f32 	%p145, %f395, %f396;
	@%p145 bra 	$L__BB0_165;
	bra.uni 	$L__BB0_164;

$L__BB0_165:
	div.rn.f32 	%f398, %f566, %f100;
	mul.f32 	%f567, %f398, 0f3F490FDB;
	mov.f32 	%f566, %f100;
	bra.uni 	$L__BB0_166;

$L__BB0_208:
	mov.b32 	%r119, %f156;
	bfe.u32 	%r689, %r119, 23, 8;
	add.s32 	%r120, %r689, -128;
	shl.b32 	%r690, %r119, 8;
	or.b32  	%r121, %r690, -2147483648;
	shr.u32 	%r122, %r120, 5;
	mov.u64 	%rd478, 0;
	mov.u32 	%r911, 0;
	mov.u64 	%rd476, __cudart_i2opi_f;
	mov.u64 	%rd477, %rd1;

$L__BB0_209:
	.pragma "nounroll";
	ld.global.nc.u32 	%r691, [%rd476];
	mad.wide.u32 	%rd415, %r691, %r121, %rd478;
	shr.u64 	%rd478, %rd415, 32;
	st.local.u32 	[%rd477], %rd415;
	add.s64 	%rd477, %rd477, 4;
	add.s64 	%rd476, %rd476, 4;
	add.s32 	%r911, %r911, 1;
	setp.ne.s32 	%p178, %r911, 6;
	@%p178 bra 	$L__BB0_209;

	add.s64 	%rd454, %rd1, 24;
	st.local.u32 	[%rd454], %rd478;
	mov.u32 	%r692, 4;
	sub.s32 	%r125, %r692, %r122;
	mov.u32 	%r693, 6;
	sub.s32 	%r694, %r693, %r122;
	mul.wide.s32 	%rd416, %r694, 4;
	add.s64 	%rd417, %rd1, %rd416;
	ld.local.u32 	%r912, [%rd417];
	ld.local.u32 	%r913, [%rd417+-4];
	and.b32  	%r128, %r120, 31;
	setp.eq.s32 	%p179, %r128, 0;
	@%p179 bra 	$L__BB0_212;

	mov.u32 	%r695, 32;
	sub.s32 	%r696, %r695, %r128;
	shr.u32 	%r697, %r913, %r696;
	shl.b32 	%r698, %r912, %r128;
	add.s32 	%r912, %r697, %r698;
	mul.wide.s32 	%rd418, %r125, 4;
	add.s64 	%rd419, %rd1, %rd418;
	ld.local.u32 	%r699, [%rd419];
	shr.u32 	%r700, %r699, %r696;
	shl.b32 	%r701, %r913, %r128;
	add.s32 	%r913, %r700, %r701;

$L__BB0_212:
	and.b32  	%r702, %r119, -2147483648;
	shr.u32 	%r703, %r913, 30;
	shl.b32 	%r704, %r912, 2;
	or.b32  	%r705, %r703, %r704;
	shr.u32 	%r706, %r705, 31;
	shr.u32 	%r707, %r912, 30;
	add.s32 	%r708, %r706, %r707;
	neg.s32 	%r709, %r708;
	setp.eq.s32 	%p180, %r702, 0;
	selp.b32 	%r914, %r708, %r709, %p180;
	setp.ne.s32 	%p181, %r706, 0;
	xor.b32  	%r710, %r702, -2147483648;
	selp.b32 	%r711, %r710, %r702, %p181;
	selp.b32 	%r712, -1, 0, %p181;
	xor.b32  	%r713, %r705, %r712;
	shl.b32 	%r714, %r913, 2;
	xor.b32  	%r715, %r714, %r712;
	cvt.u64.u32 	%rd420, %r713;
	cvt.u64.u32 	%rd421, %r715;
	bfi.b64 	%rd422, %rd420, %rd421, 32, 32;
	cvt.rn.f64.s64 	%fd23, %rd422;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f475, %fd24;
	setp.eq.s32 	%p182, %r711, 0;
	neg.f32 	%f476, %f475;
	selp.f32 	%f587, %f475, %f476, %p182;

$L__BB0_214:
	and.b32  	%r135, %r914, 1;
	setp.eq.s32 	%p183, %r135, 0;
	selp.f32 	%f173, %f587, 0f3F800000, %p183;
	mul.rn.f32 	%f174, %f587, %f587;
	mov.f32 	%f588, 0fB94D4153;
	@%p183 bra 	$L__BB0_216;

	mov.f32 	%f479, 0fBAB607ED;
	mov.f32 	%f480, 0f37CBAC00;
	fma.rn.f32 	%f588, %f480, %f174, %f479;

$L__BB0_216:
	selp.f32 	%f481, 0f3C0885E4, 0f3D2AAABB, %p183;
	fma.rn.f32 	%f482, %f588, %f174, %f481;
	selp.f32 	%f483, 0fBE2AAAA8, 0fBEFFFFFF, %p183;
	fma.rn.f32 	%f484, %f482, %f174, %f483;
	fma.rn.f32 	%f486, %f174, %f173, %f471;
	fma.rn.f32 	%f589, %f484, %f486, %f173;
	and.b32  	%r717, %r914, 2;
	setp.eq.s32 	%p185, %r717, 0;
	@%p185 bra 	$L__BB0_218;

	mov.f32 	%f488, 0fBF800000;
	fma.rn.f32 	%f589, %f589, %f488, %f471;

$L__BB0_218:
	mul.f32 	%f489, %f157, 0f3F22F983;
	cvt.rni.s32.f32 	%r922, %f489;
	cvt.rn.f32.s32 	%f490, %r922;
	fma.rn.f32 	%f492, %f490, %f456, %f157;
	fma.rn.f32 	%f494, %f490, %f458, %f492;
	fma.rn.f32 	%f593, %f490, %f460, %f494;
	abs.f32 	%f181, %f157;
	setp.leu.f32 	%p186, %f181, 0f47CE4780;
	mov.u32 	%r918, %r922;
	mov.f32 	%f590, %f593;
	@%p186 bra 	$L__BB0_226;

	setp.eq.f32 	%p187, %f181, 0f7F800000;
	@%p187 bra 	$L__BB0_225;
	bra.uni 	$L__BB0_220;

$L__BB0_225:
	mul.rn.f32 	%f590, %f157, %f471;
	mov.u32 	%r918, 0;
	bra.uni 	$L__BB0_226;

$L__BB0_220:
	mov.b32 	%r137, %f157;
	bfe.u32 	%r719, %r137, 23, 8;
	add.s32 	%r138, %r719, -128;
	shl.b32 	%r720, %r137, 8;
	or.b32  	%r139, %r720, -2147483648;
	shr.u32 	%r140, %r138, 5;
	mov.u64 	%rd481, 0;
	mov.u32 	%r915, 0;
	mov.u64 	%rd479, __cudart_i2opi_f;
	mov.u64 	%rd480, %rd1;

$L__BB0_221:
	.pragma "nounroll";
	ld.global.nc.u32 	%r721, [%rd479];
	mad.wide.u32 	%rd425, %r721, %r139, %rd481;
	shr.u64 	%rd481, %rd425, 32;
	st.local.u32 	[%rd480], %rd425;
	add.s64 	%rd480, %rd480, 4;
	add.s64 	%rd479, %rd479, 4;
	add.s32 	%r915, %r915, 1;
	setp.ne.s32 	%p188, %r915, 6;
	@%p188 bra 	$L__BB0_221;

	add.s64 	%rd453, %rd1, 24;
	st.local.u32 	[%rd453], %rd481;
	mov.u32 	%r722, 4;
	sub.s32 	%r143, %r722, %r140;
	mov.u32 	%r723, 6;
	sub.s32 	%r724, %r723, %r140;
	mul.wide.s32 	%rd426, %r724, 4;
	add.s64 	%rd427, %rd1, %rd426;
	ld.local.u32 	%r916, [%rd427];
	ld.local.u32 	%r917, [%rd427+-4];
	and.b32  	%r146, %r138, 31;
	setp.eq.s32 	%p189, %r146, 0;
	@%p189 bra 	$L__BB0_224;

	mov.u32 	%r725, 32;
	sub.s32 	%r726, %r725, %r146;
	shr.u32 	%r727, %r917, %r726;
	shl.b32 	%r728, %r916, %r146;
	add.s32 	%r916, %r727, %r728;
	mul.wide.s32 	%rd428, %r143, 4;
	add.s64 	%rd429, %rd1, %rd428;
	ld.local.u32 	%r729, [%rd429];
	shr.u32 	%r730, %r729, %r726;
	shl.b32 	%r731, %r917, %r146;
	add.s32 	%r917, %r730, %r731;

$L__BB0_224:
	and.b32  	%r732, %r137, -2147483648;
	shr.u32 	%r733, %r917, 30;
	shl.b32 	%r734, %r916, 2;
	or.b32  	%r735, %r733, %r734;
	shr.u32 	%r736, %r735, 31;
	shr.u32 	%r737, %r916, 30;
	add.s32 	%r738, %r736, %r737;
	neg.s32 	%r739, %r738;
	setp.eq.s32 	%p190, %r732, 0;
	selp.b32 	%r918, %r738, %r739, %p190;
	setp.ne.s32 	%p191, %r736, 0;
	xor.b32  	%r740, %r732, -2147483648;
	selp.b32 	%r741, %r740, %r732, %p191;
	selp.b32 	%r742, -1, 0, %p191;
	xor.b32  	%r743, %r735, %r742;
	shl.b32 	%r744, %r917, 2;
	xor.b32  	%r745, %r744, %r742;
	cvt.u64.u32 	%rd430, %r743;
	cvt.u64.u32 	%rd431, %r745;
	bfi.b64 	%rd432, %rd430, %rd431, 32, 32;
	cvt.rn.f64.s64 	%fd25, %rd432;
	mul.f64 	%fd26, %fd25, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f496, %fd26;
	setp.eq.s32 	%p192, %r741, 0;
	neg.f32 	%f497, %f496;
	selp.f32 	%f590, %f496, %f497, %p192;

$L__BB0_226:
	add.s32 	%r153, %r918, 1;
	and.b32  	%r154, %r153, 1;
	setp.eq.s32 	%p193, %r154, 0;
	selp.f32 	%f185, %f590, 0f3F800000, %p193;
	mul.rn.f32 	%f186, %f590, %f590;
	mov.f32 	%f591, 0fB94D4153;
	@%p193 bra 	$L__BB0_228;

	mov.f32 	%f500, 0fBAB607ED;
	mov.f32 	%f501, 0f37CBAC00;
	fma.rn.f32 	%f591, %f501, %f186, %f500;

$L__BB0_228:
	selp.f32 	%f502, 0f3C0885E4, 0f3D2AAABB, %p193;
	fma.rn.f32 	%f503, %f591, %f186, %f502;
	selp.f32 	%f504, 0fBE2AAAA8, 0fBEFFFFFF, %p193;
	fma.rn.f32 	%f505, %f503, %f186, %f504;
	fma.rn.f32 	%f507, %f186, %f185, %f471;
	fma.rn.f32 	%f592, %f505, %f507, %f185;
	and.b32  	%r747, %r153, 2;
	setp.eq.s32 	%p195, %r747, 0;
	@%p195 bra 	$L__BB0_230;

	mov.f32 	%f509, 0fBF800000;
	fma.rn.f32 	%f592, %f592, %f509, %f471;

$L__BB0_230:
	@%p186 bra 	$L__BB0_238;

	setp.eq.f32 	%p197, %f181, 0f7F800000;
	@%p197 bra 	$L__BB0_237;
	bra.uni 	$L__BB0_232;

$L__BB0_237:
	mul.rn.f32 	%f593, %f157, %f471;
	mov.u32 	%r922, 0;
	bra.uni 	$L__BB0_238;

$L__BB0_232:
	mov.b32 	%r155, %f157;
	bfe.u32 	%r749, %r155, 23, 8;
	add.s32 	%r156, %r749, -128;
	shl.b32 	%r750, %r155, 8;
	or.b32  	%r157, %r750, -2147483648;
	shr.u32 	%r158, %r156, 5;
	mov.u64 	%rd484, 0;
	mov.u32 	%r919, 0;
	mov.u64 	%rd482, __cudart_i2opi_f;
	mov.u64 	%rd483, %rd1;

$L__BB0_233:
	.pragma "nounroll";
	ld.global.nc.u32 	%r751, [%rd482];
	mad.wide.u32 	%rd435, %r751, %r157, %rd484;
	shr.u64 	%rd484, %rd435, 32;
	st.local.u32 	[%rd483], %rd435;
	add.s64 	%rd483, %rd483, 4;
	add.s64 	%rd482, %rd482, 4;
	add.s32 	%r919, %r919, 1;
	setp.ne.s32 	%p198, %r919, 6;
	@%p198 bra 	$L__BB0_233;

	add.s64 	%rd452, %rd1, 24;
	st.local.u32 	[%rd452], %rd484;
	mov.u32 	%r752, 4;
	sub.s32 	%r161, %r752, %r158;
	mov.u32 	%r753, 6;
	sub.s32 	%r754, %r753, %r158;
	mul.wide.s32 	%rd436, %r754, 4;
	add.s64 	%rd437, %rd1, %rd436;
	ld.local.u32 	%r920, [%rd437];
	ld.local.u32 	%r921, [%rd437+-4];
	and.b32  	%r164, %r156, 31;
	setp.eq.s32 	%p199, %r164, 0;
	@%p199 bra 	$L__BB0_236;

	mov.u32 	%r755, 32;
	sub.s32 	%r756, %r755, %r164;
	shr.u32 	%r757, %r921, %r756;
	shl.b32 	%r758, %r920, %r164;
	add.s32 	%r920, %r757, %r758;
	mul.wide.s32 	%rd438, %r161, 4;
	add.s64 	%rd439, %rd1, %rd438;
	ld.local.u32 	%r759, [%rd439];
	shr.u32 	%r760, %r759, %r756;
	shl.b32 	%r761, %r921, %r164;
	add.s32 	%r921, %r760, %r761;

$L__BB0_236:
	and.b32  	%r762, %r155, -2147483648;
	shr.u32 	%r763, %r921, 30;
	shl.b32 	%r764, %r920, 2;
	or.b32  	%r765, %r763, %r764;
	shr.u32 	%r766, %r765, 31;
	shr.u32 	%r767, %r920, 30;
	add.s32 	%r768, %r766, %r767;
	neg.s32 	%r769, %r768;
	setp.eq.s32 	%p200, %r762, 0;
	selp.b32 	%r922, %r768, %r769, %p200;
	setp.ne.s32 	%p201, %r766, 0;
	xor.b32  	%r770, %r762, -2147483648;
	selp.b32 	%r771, %r770, %r762, %p201;
	selp.b32 	%r772, -1, 0, %p201;
	xor.b32  	%r773, %r765, %r772;
	shl.b32 	%r774, %r921, 2;
	xor.b32  	%r775, %r774, %r772;
	cvt.u64.u32 	%rd440, %r773;
	cvt.u64.u32 	%rd441, %r775;
	bfi.b64 	%rd442, %rd440, %rd441, 32, 32;
	cvt.rn.f64.s64 	%fd27, %rd442;
	mul.f64 	%fd28, %fd27, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f510, %fd28;
	setp.eq.s32 	%p202, %r771, 0;
	neg.f32 	%f511, %f510;
	selp.f32 	%f593, %f510, %f511, %p202;

$L__BB0_238:
	and.b32  	%r171, %r922, 1;
	setp.eq.s32 	%p203, %r171, 0;
	selp.f32 	%f195, %f593, 0f3F800000, %p203;
	mul.rn.f32 	%f196, %f593, %f593;
	mov.f32 	%f594, 0fB94D4153;
	@%p203 bra 	$L__BB0_240;

	mov.f32 	%f514, 0fBAB607ED;
	mov.f32 	%f515, 0f37CBAC00;
	fma.rn.f32 	%f594, %f515, %f196, %f514;

$L__BB0_240:
	selp.f32 	%f516, 0f3C0885E4, 0f3D2AAABB, %p203;
	fma.rn.f32 	%f517, %f594, %f196, %f516;
	selp.f32 	%f518, 0fBE2AAAA8, 0fBEFFFFFF, %p203;
	fma.rn.f32 	%f519, %f517, %f196, %f518;
	fma.rn.f32 	%f521, %f196, %f195, %f471;
	fma.rn.f32 	%f601, %f519, %f521, %f195;
	and.b32  	%r777, %r922, 2;
	setp.eq.s32 	%p205, %r777, 0;
	@%p205 bra 	$L__BB0_242;

	mov.f32 	%f523, 0fBF800000;
	fma.rn.f32 	%f601, %f601, %f523, %f471;

$L__BB0_242:
	ld.const.v4.f32 	{%f596, %f597, %f598, %f527}, [global+80];
	mul.f32 	%f602, %f589, %f592;
	mul.f32 	%f600, %f586, %f592;
	mov.f32 	%f603, 0f7F7FFFFF;
	mov.f32 	%f599, 0f38D1B717;
	bra.uni 	$L__BB0_243;

$L__BB0_66:
	abs.f32 	%f38, %f559;
	mul.f32 	%f39, %f37, 0f4B000000;
	setp.lt.f32 	%p40, %f38, %f37;
	@%p40 bra 	$L__BB0_78;

	setp.le.f32 	%p41, %f38, %f39;
	setp.leu.f32 	%p42, %f37, 0f00000000;
	or.pred  	%p43, %p42, %p41;
	mov.b32 	%r14, %f38;
	setp.gt.u32 	%p44, %r14, 2139095039;
	or.pred  	%p45, %p44, %p43;
	@%p45 bra 	$L__BB0_72;
	bra.uni 	$L__BB0_68;

$L__BB0_72:
	div.approx.f32 	%f283, %f38, %f37;
	cvt.rzi.f32.f32 	%f558, %f283;
	neg.f32 	%f42, %f37;
	fma.rn.f32 	%f43, %f42, %f558, %f38;
	mov.b32 	%r24, %f43;
	mov.b32 	%r512, %f37;
	setp.lt.u32 	%p48, %r24, %r512;
	@%p48 bra 	$L__BB0_77;

	setp.gt.u32 	%p49, %r24, -2147483648;
	@%p49 bra 	$L__BB0_76;
	bra.uni 	$L__BB0_74;

$L__BB0_76:
	add.f32 	%f289, %f558, 0fBF800000;
	add.f32 	%f290, %f289, 0fBF800000;
	setp.lt.f32 	%p52, %f43, %f42;
	selp.f32 	%f558, %f290, %f289, %p52;
	bra.uni 	$L__BB0_77;

$L__BB0_80:
	setp.eq.f32 	%p55, %f275, 0f00000000;
	mov.f32 	%f560, 0f00000000;
	@%p55 bra 	$L__BB0_83;

	setp.lt.f32 	%p56, %f275, 0f00000000;
	selp.b32 	%r517, -1, 0, %p56;
	mov.b32 	%r518, %f275;
	add.s32 	%r519, %r517, %r518;
	setp.gt.f32 	%p57, %f275, 0f00000000;
	selp.b32 	%r520, -1, 0, %p57;
	add.s32 	%r521, %r519, %r520;
	mov.b32 	%f560, %r521;

$L__BB0_83:
	setp.lt.f32 	%p58, %f560, %f559;
	selp.f32 	%f294, %f560, %f559, %p58;
	setp.lt.f32 	%p59, %f559, 0f00000000;
	selp.f32 	%f561, 0f00000000, %f294, %p59;
	bra.uni 	$L__BB0_84;

$L__BB0_164:
	div.rn.f32 	%f397, %f100, %f566;
	fma.rn.f32 	%f567, %f397, 0fBF490FDB, 0f3FC90FDB;

$L__BB0_166:
	mul.f32 	%f399, %f567, 0f3F22F983;
	cvt.rni.s32.f32 	%r906, %f399;
	cvt.rn.f32.s32 	%f400, %r906;
	mov.f32 	%f401, 0fBFC90FDA;
	fma.rn.f32 	%f402, %f400, %f401, %f567;
	mov.f32 	%f403, 0fB3A22168;
	fma.rn.f32 	%f404, %f400, %f403, %f402;
	mov.f32 	%f405, 0fA7C234C5;
	fma.rn.f32 	%f571, %f400, %f405, %f404;
	abs.f32 	%f107, %f567;
	setp.leu.f32 	%p146, %f107, 0f47CE4780;
	mov.u32 	%r902, %r906;
	mov.f32 	%f568, %f571;
	@%p146 bra 	$L__BB0_174;

	setp.eq.f32 	%p147, %f107, 0f7F800000;
	@%p147 bra 	$L__BB0_173;
	bra.uni 	$L__BB0_168;

$L__BB0_173:
	mov.f32 	%f408, 0f00000000;
	mul.rn.f32 	%f568, %f567, %f408;
	mov.u32 	%r902, 0;
	bra.uni 	$L__BB0_174;

$L__BB0_68:
	shr.u32 	%r500, %r14, 23;
	mov.b32 	%r15, %f39;
	shr.u32 	%r501, %r15, 23;
	and.b32  	%r502, %r14, 8388607;
	or.b32  	%r886, %r502, 8388608;
	add.s32 	%r503, %r500, 23;
	sub.s32 	%r884, %r503, %r501;
	setp.eq.s32 	%p46, %r884, 0;
	@%p46 bra 	$L__BB0_71;

	and.b32  	%r504, %r15, 8388607;
	or.b32  	%r18, %r504, 8388608;

$L__BB0_70:
	min.s32 	%r505, %r884, 8;
	shl.b32 	%r506, %r886, %r505;
	rem.u32 	%r886, %r506, %r18;
	sub.s32 	%r884, %r884, %r505;
	setp.ne.s32 	%p47, %r884, 0;
	@%p47 bra 	$L__BB0_70;

$L__BB0_71:
	and.b32  	%r507, %r15, -8388608;
	mov.b32 	%f279, %r507;
	cvt.rn.f32.u32 	%f280, %r886;
	mul.f32 	%f281, %f280, 0f28800000;
	mul.f32 	%f282, %f281, %f279;
	mov.b32 	%r508, %f282;
	mov.b32 	%r509, %f559;
	and.b32  	%r510, %r509, -2147483648;
	or.b32  	%r511, %r510, %r508;
	mov.b32 	%f559, %r511;
	bra.uni 	$L__BB0_78;

$L__BB0_168:
	mov.b32 	%r65, %f567;
	bfe.u32 	%r599, %r65, 23, 8;
	add.s32 	%r66, %r599, -128;
	shl.b32 	%r600, %r65, 8;
	or.b32  	%r67, %r600, -2147483648;
	shr.u32 	%r68, %r66, 5;
	mov.u64 	%rd469, 0;
	mov.u32 	%r899, 0;
	mov.u64 	%rd467, __cudart_i2opi_f;
	mov.u64 	%rd468, %rd1;

$L__BB0_169:
	.pragma "nounroll";
	ld.global.nc.u32 	%r601, [%rd467];
	mad.wide.u32 	%rd385, %r601, %r67, %rd469;
	shr.u64 	%rd469, %rd385, 32;
	st.local.u32 	[%rd468], %rd385;
	add.s64 	%rd468, %rd468, 4;
	add.s64 	%rd467, %rd467, 4;
	add.s32 	%r899, %r899, 1;
	setp.ne.s32 	%p148, %r899, 6;
	@%p148 bra 	$L__BB0_169;

	add.s64 	%rd451, %rd1, 24;
	st.local.u32 	[%rd451], %rd469;
	mov.u32 	%r602, 4;
	sub.s32 	%r71, %r602, %r68;
	mov.u32 	%r603, 6;
	sub.s32 	%r604, %r603, %r68;
	mul.wide.s32 	%rd386, %r604, 4;
	add.s64 	%rd387, %rd1, %rd386;
	ld.local.u32 	%r900, [%rd387];
	ld.local.u32 	%r901, [%rd387+-4];
	and.b32  	%r74, %r66, 31;
	setp.eq.s32 	%p149, %r74, 0;
	@%p149 bra 	$L__BB0_172;

	mov.u32 	%r605, 32;
	sub.s32 	%r606, %r605, %r74;
	shr.u32 	%r607, %r901, %r606;
	shl.b32 	%r608, %r900, %r74;
	add.s32 	%r900, %r607, %r608;
	mul.wide.s32 	%rd388, %r71, 4;
	add.s64 	%rd389, %rd1, %rd388;
	ld.local.u32 	%r609, [%rd389];
	shr.u32 	%r610, %r609, %r606;
	shl.b32 	%r611, %r901, %r74;
	add.s32 	%r901, %r610, %r611;

$L__BB0_172:
	and.b32  	%r612, %r65, -2147483648;
	shr.u32 	%r613, %r901, 30;
	shl.b32 	%r614, %r900, 2;
	or.b32  	%r615, %r613, %r614;
	shr.u32 	%r616, %r615, 31;
	shr.u32 	%r617, %r900, 30;
	add.s32 	%r618, %r616, %r617;
	neg.s32 	%r619, %r618;
	setp.eq.s32 	%p150, %r612, 0;
	selp.b32 	%r902, %r618, %r619, %p150;
	setp.ne.s32 	%p151, %r616, 0;
	xor.b32  	%r620, %r612, -2147483648;
	selp.b32 	%r621, %r620, %r612, %p151;
	selp.b32 	%r622, -1, 0, %p151;
	xor.b32  	%r623, %r615, %r622;
	shl.b32 	%r624, %r901, 2;
	xor.b32  	%r625, %r624, %r622;
	cvt.u64.u32 	%rd390, %r623;
	cvt.u64.u32 	%rd391, %r625;
	bfi.b64 	%rd392, %rd390, %rd391, 32, 32;
	cvt.rn.f64.s64 	%fd17, %rd392;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f406, %fd18;
	setp.eq.s32 	%p152, %r621, 0;
	neg.f32 	%f407, %f406;
	selp.f32 	%f568, %f406, %f407, %p152;

$L__BB0_174:
	add.s32 	%r81, %r902, 1;
	and.b32  	%r82, %r81, 1;
	setp.eq.s32 	%p153, %r82, 0;
	selp.f32 	%f111, %f568, 0f3F800000, %p153;
	mul.rn.f32 	%f112, %f568, %f568;
	mov.f32 	%f569, 0fB94D4153;
	@%p153 bra 	$L__BB0_176;

	mov.f32 	%f410, 0fBAB607ED;
	mov.f32 	%f411, 0f37CBAC00;
	fma.rn.f32 	%f569, %f411, %f112, %f410;

$L__BB0_176:
	selp.f32 	%f412, 0f3C0885E4, 0f3D2AAABB, %p153;
	fma.rn.f32 	%f413, %f569, %f112, %f412;
	selp.f32 	%f414, 0fBE2AAAA8, 0fBEFFFFFF, %p153;
	fma.rn.f32 	%f415, %f413, %f112, %f414;
	mov.f32 	%f416, 0f00000000;
	fma.rn.f32 	%f417, %f112, %f111, %f416;
	fma.rn.f32 	%f570, %f415, %f417, %f111;
	and.b32  	%r627, %r81, 2;
	setp.eq.s32 	%p155, %r627, 0;
	@%p155 bra 	$L__BB0_178;

	mov.f32 	%f419, 0fBF800000;
	fma.rn.f32 	%f570, %f570, %f419, %f416;

$L__BB0_178:
	@%p146 bra 	$L__BB0_186;

	setp.eq.f32 	%p157, %f107, 0f7F800000;
	@%p157 bra 	$L__BB0_185;
	bra.uni 	$L__BB0_180;

$L__BB0_185:
	mul.rn.f32 	%f571, %f567, %f416;
	mov.u32 	%r906, 0;
	bra.uni 	$L__BB0_186;

$L__BB0_180:
	mov.b32 	%r83, %f567;
	bfe.u32 	%r629, %r83, 23, 8;
	add.s32 	%r84, %r629, -128;
	shl.b32 	%r630, %r83, 8;
	or.b32  	%r85, %r630, -2147483648;
	shr.u32 	%r86, %r84, 5;
	mov.u64 	%rd472, 0;
	mov.u32 	%r903, 0;
	mov.u64 	%rd470, __cudart_i2opi_f;
	mov.u64 	%rd471, %rd1;

$L__BB0_181:
	.pragma "nounroll";
	ld.global.nc.u32 	%r631, [%rd470];
	mad.wide.u32 	%rd395, %r631, %r85, %rd472;
	shr.u64 	%rd472, %rd395, 32;
	st.local.u32 	[%rd471], %rd395;
	add.s64 	%rd471, %rd471, 4;
	add.s64 	%rd470, %rd470, 4;
	add.s32 	%r903, %r903, 1;
	setp.ne.s32 	%p158, %r903, 6;
	@%p158 bra 	$L__BB0_181;

	add.s64 	%rd450, %rd1, 24;
	st.local.u32 	[%rd450], %rd472;
	mov.u32 	%r632, 4;
	sub.s32 	%r89, %r632, %r86;
	mov.u32 	%r633, 6;
	sub.s32 	%r634, %r633, %r86;
	mul.wide.s32 	%rd396, %r634, 4;
	add.s64 	%rd397, %rd1, %rd396;
	ld.local.u32 	%r904, [%rd397];
	ld.local.u32 	%r905, [%rd397+-4];
	and.b32  	%r92, %r84, 31;
	setp.eq.s32 	%p159, %r92, 0;
	@%p159 bra 	$L__BB0_184;

	mov.u32 	%r635, 32;
	sub.s32 	%r636, %r635, %r92;
	shr.u32 	%r637, %r905, %r636;
	shl.b32 	%r638, %r904, %r92;
	add.s32 	%r904, %r637, %r638;
	mul.wide.s32 	%rd398, %r89, 4;
	add.s64 	%rd399, %rd1, %rd398;
	ld.local.u32 	%r639, [%rd399];
	shr.u32 	%r640, %r639, %r636;
	shl.b32 	%r641, %r905, %r92;
	add.s32 	%r905, %r640, %r641;

$L__BB0_184:
	and.b32  	%r642, %r83, -2147483648;
	shr.u32 	%r643, %r905, 30;
	shl.b32 	%r644, %r904, 2;
	or.b32  	%r645, %r643, %r644;
	shr.u32 	%r646, %r645, 31;
	shr.u32 	%r647, %r904, 30;
	add.s32 	%r648, %r646, %r647;
	neg.s32 	%r649, %r648;
	setp.eq.s32 	%p160, %r642, 0;
	selp.b32 	%r906, %r648, %r649, %p160;
	setp.ne.s32 	%p161, %r646, 0;
	xor.b32  	%r650, %r642, -2147483648;
	selp.b32 	%r651, %r650, %r642, %p161;
	selp.b32 	%r652, -1, 0, %p161;
	xor.b32  	%r653, %r645, %r652;
	shl.b32 	%r654, %r905, 2;
	xor.b32  	%r655, %r654, %r652;
	cvt.u64.u32 	%rd400, %r653;
	cvt.u64.u32 	%rd401, %r655;
	bfi.b64 	%rd402, %rd400, %rd401, 32, 32;
	cvt.rn.f64.s64 	%fd19, %rd402;
	mul.f64 	%fd20, %fd19, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f420, %fd20;
	setp.eq.s32 	%p162, %r651, 0;
	neg.f32 	%f421, %f420;
	selp.f32 	%f571, %f420, %f421, %p162;

$L__BB0_186:
	and.b32  	%r99, %r906, 1;
	setp.eq.s32 	%p163, %r99, 0;
	selp.f32 	%f121, %f571, 0f3F800000, %p163;
	mul.rn.f32 	%f122, %f571, %f571;
	mov.f32 	%f572, 0fB94D4153;
	@%p163 bra 	$L__BB0_188;

	mov.f32 	%f424, 0fBAB607ED;
	mov.f32 	%f425, 0f37CBAC00;
	fma.rn.f32 	%f572, %f425, %f122, %f424;

$L__BB0_188:
	selp.f32 	%f426, 0f3C0885E4, 0f3D2AAABB, %p163;
	fma.rn.f32 	%f427, %f572, %f122, %f426;
	selp.f32 	%f428, 0fBE2AAAA8, 0fBEFFFFFF, %p163;
	fma.rn.f32 	%f429, %f427, %f122, %f428;
	fma.rn.f32 	%f431, %f122, %f121, %f416;
	fma.rn.f32 	%f573, %f429, %f431, %f121;
	and.b32  	%r657, %r906, 2;
	setp.eq.s32 	%p165, %r657, 0;
	@%p165 bra 	$L__BB0_190;

	mov.f32 	%f433, 0fBF800000;
	fma.rn.f32 	%f573, %f573, %f433, %f416;

$L__BB0_190:
	mul.f32 	%f577, %f566, %f573;
	mul.f32 	%f576, %f566, %f570;
	bra.uni 	$L__BB0_192;

$L__BB0_74:
	add.f32 	%f558, %f558, 0f3F800000;
	add.f32 	%f284, %f37, %f37;
	setp.ltu.f32 	%p50, %f43, %f284;
	@%p50 bra 	$L__BB0_77;

	add.f32 	%f285, %f558, 0f3F800000;
	mov.f32 	%f286, 0fC0400000;
	fma.rn.f32 	%f287, %f286, %f37, %f43;
	setp.ge.f32 	%p51, %f287, 0f00000000;
	add.f32 	%f288, %f285, 0f3F800000;
	selp.f32 	%f558, %f288, %f285, %p51;

$L__BB0_77:
	fma.rn.f32 	%f291, %f42, %f558, %f38;
	mov.b32 	%r513, %f291;
	mov.b32 	%r514, %f559;
	and.b32  	%r515, %r514, -2147483648;
	or.b32  	%r516, %r515, %r513;
	mov.b32 	%f559, %r516;

$L__BB0_78:
	add.f32 	%f292, %f275, %f559;
	setp.lt.f32 	%p53, %f559, 0f00000000;
	selp.f32 	%f561, %f292, %f559, %p53;

$L__BB0_84:
	and.b32  	%r522, %r13, 4;
	setp.eq.s32 	%p60, %r522, 0;
	abs.f32 	%f56, %f276;
	@%p60 bra 	$L__BB0_98;
	bra.uni 	$L__BB0_85;

$L__BB0_98:
	setp.gtu.f32 	%p75, %f56, 0f7F800000;
	@%p75 bra 	$L__BB0_101;
	bra.uni 	$L__BB0_99;

$L__BB0_101:
	add.f32 	%f564, %f276, 0f00000000;
	bra.uni 	$L__BB0_102;

$L__BB0_85:
	abs.f32 	%f57, %f563;
	mul.f32 	%f58, %f56, 0f4B000000;
	setp.lt.f32 	%p61, %f57, %f56;
	@%p61 bra 	$L__BB0_97;

	setp.le.f32 	%p62, %f57, %f58;
	setp.leu.f32 	%p63, %f56, 0f00000000;
	or.pred  	%p64, %p63, %p62;
	mov.b32 	%r25, %f57;
	setp.gt.u32 	%p65, %r25, 2139095039;
	or.pred  	%p66, %p65, %p64;
	@%p66 bra 	$L__BB0_91;
	bra.uni 	$L__BB0_87;

$L__BB0_91:
	div.approx.f32 	%f299, %f57, %f56;
	cvt.rzi.f32.f32 	%f562, %f299;
	neg.f32 	%f61, %f56;
	fma.rn.f32 	%f62, %f61, %f562, %f57;
	mov.b32 	%r35, %f62;
	mov.b32 	%r535, %f56;
	setp.lt.u32 	%p69, %r35, %r535;
	@%p69 bra 	$L__BB0_96;

	setp.gt.u32 	%p70, %r35, -2147483648;
	@%p70 bra 	$L__BB0_95;
	bra.uni 	$L__BB0_93;

$L__BB0_95:
	add.f32 	%f305, %f562, 0fBF800000;
	add.f32 	%f306, %f305, 0fBF800000;
	setp.lt.f32 	%p73, %f62, %f61;
	selp.f32 	%f562, %f306, %f305, %p73;
	bra.uni 	$L__BB0_96;

$L__BB0_99:
	setp.eq.f32 	%p76, %f276, 0f00000000;
	mov.f32 	%f564, 0f00000000;
	@%p76 bra 	$L__BB0_102;

	setp.lt.f32 	%p77, %f276, 0f00000000;
	selp.b32 	%r540, -1, 0, %p77;
	mov.b32 	%r541, %f276;
	add.s32 	%r542, %r540, %r541;
	setp.gt.f32 	%p78, %f276, 0f00000000;
	selp.b32 	%r543, -1, 0, %p78;
	add.s32 	%r544, %r542, %r543;
	mov.b32 	%f564, %r544;

$L__BB0_102:
	setp.lt.f32 	%p79, %f564, %f563;
	selp.f32 	%f310, %f564, %f563, %p79;
	setp.lt.f32 	%p80, %f563, 0f00000000;
	selp.f32 	%f565, 0f00000000, %f310, %p80;
	bra.uni 	$L__BB0_103;

$L__BB0_87:
	shr.u32 	%r523, %r25, 23;
	mov.b32 	%r26, %f58;
	shr.u32 	%r524, %r26, 23;
	and.b32  	%r525, %r25, 8388607;
	or.b32  	%r889, %r525, 8388608;
	add.s32 	%r526, %r523, 23;
	sub.s32 	%r887, %r526, %r524;
	setp.eq.s32 	%p67, %r887, 0;
	@%p67 bra 	$L__BB0_90;

	and.b32  	%r527, %r26, 8388607;
	or.b32  	%r29, %r527, 8388608;

$L__BB0_89:
	min.s32 	%r528, %r887, 8;
	shl.b32 	%r529, %r889, %r528;
	rem.u32 	%r889, %r529, %r29;
	sub.s32 	%r887, %r887, %r528;
	setp.ne.s32 	%p68, %r887, 0;
	@%p68 bra 	$L__BB0_89;

$L__BB0_90:
	and.b32  	%r530, %r26, -8388608;
	mov.b32 	%f295, %r530;
	cvt.rn.f32.u32 	%f296, %r889;
	mul.f32 	%f297, %f296, 0f28800000;
	mul.f32 	%f298, %f297, %f295;
	mov.b32 	%r531, %f298;
	mov.b32 	%r532, %f563;
	and.b32  	%r533, %r532, -2147483648;
	or.b32  	%r534, %r533, %r531;
	mov.b32 	%f563, %r534;
	bra.uni 	$L__BB0_97;

$L__BB0_93:
	add.f32 	%f562, %f562, 0f3F800000;
	add.f32 	%f300, %f56, %f56;
	setp.ltu.f32 	%p71, %f62, %f300;
	@%p71 bra 	$L__BB0_96;

	add.f32 	%f301, %f562, 0f3F800000;
	mov.f32 	%f302, 0fC0400000;
	fma.rn.f32 	%f303, %f302, %f56, %f62;
	setp.ge.f32 	%p72, %f303, 0f00000000;
	add.f32 	%f304, %f301, 0f3F800000;
	selp.f32 	%f562, %f304, %f301, %p72;

$L__BB0_96:
	fma.rn.f32 	%f307, %f61, %f562, %f57;
	mov.b32 	%r536, %f307;
	mov.b32 	%r537, %f563;
	and.b32  	%r538, %r537, -2147483648;
	or.b32  	%r539, %r538, %r536;
	mov.b32 	%f563, %r539;

$L__BB0_97:
	add.f32 	%f308, %f276, %f563;
	setp.lt.f32 	%p74, %f563, 0f00000000;
	selp.f32 	%f565, %f308, %f563, %p74;

$L__BB0_103:
	cvt.rmi.f32.f32 	%f311, %f561;
	sub.f32 	%f75, %f561, %f311;
	cvt.rmi.f32.f32 	%f312, %f565;
	sub.f32 	%f76, %f565, %f312;
	ld.global.v2.u32 	{%r894, %r546}, [%rd7+32];
	add.s32 	%r548, %r546, -1;
	cvt.rzi.u32.f32 	%r549, %f565;
	min.u32 	%r37, %r549, %r548;
	add.s32 	%r550, %r37, 1;
	min.u32 	%r38, %r550, %r548;
	add.s32 	%r551, %r894, -1;
	cvt.rzi.u32.f32 	%r552, %f561;
	min.u32 	%r39, %r552, %r551;
	add.s32 	%r553, %r39, 1;
	min.u32 	%r40, %r553, %r551;
	mul.lo.s32 	%r891, %r37, %r894;
	add.s32 	%r554, %r39, %r891;
	mad.lo.s32 	%r893, %r546, %r894, -1;
	min.u32 	%r555, %r554, %r893;
	ld.global.u64 	%rd459, [%rd7+-24];
	mul.wide.s32 	%rd321, %r555, 16;
	add.s64 	%rd322, %rd459, %rd321;
	ld.v4.f32 	{%f313, %f314, %f315, %f316}, [%rd322];
	mov.f32 	%f321, 0f3F800000;
	sub.f32 	%f77, %f321, %f75;
	mul.f32 	%f322, %f77, %f313;
	mul.f32 	%f323, %f77, %f314;
	mul.f32 	%f324, %f77, %f315;
	mul.f32 	%f325, %f77, %f316;
	sub.f32 	%f78, %f321, %f76;
	mul.f32 	%f79, %f78, %f322;
	mul.f32 	%f80, %f78, %f323;
	mul.f32 	%f81, %f78, %f324;
	mul.f32 	%f82, %f78, %f325;
	setp.ltu.f32 	%p81, %f79, 0f00000000;
	mov.u16 	%rs44, 0;
	mov.u16 	%rs40, %rs44;
	@%p81 bra 	$L__BB0_105;

	abs.f32 	%f326, %f79;
	setp.lt.f32 	%p82, %f326, 0f7F800000;
	selp.u16 	%rs40, 1, 0, %p82;

$L__BB0_105:
	setp.eq.s16 	%p83, %rs40, 0;
	@%p83 bra 	$L__BB0_115;

	setp.ltu.f32 	%p84, %f80, 0f00000000;
	mov.u16 	%rs44, 0;
	mov.u16 	%rs41, %rs44;
	@%p84 bra 	$L__BB0_108;

	abs.f32 	%f327, %f80;
	setp.lt.f32 	%p85, %f327, 0f7F800000;
	selp.u16 	%rs41, 1, 0, %p85;

$L__BB0_108:
	setp.eq.s16 	%p86, %rs41, 0;
	@%p86 bra 	$L__BB0_115;

	setp.ltu.f32 	%p87, %f81, 0f00000000;
	mov.u16 	%rs44, 0;
	mov.u16 	%rs42, %rs44;
	@%p87 bra 	$L__BB0_111;

	abs.f32 	%f328, %f81;
	setp.lt.f32 	%p88, %f328, 0f7F800000;
	selp.u16 	%rs42, 1, 0, %p88;

$L__BB0_111:
	setp.eq.s16 	%p89, %rs42, 0;
	@%p89 bra 	$L__BB0_115;

	setp.ltu.f32 	%p90, %f82, 0f00000000;
	mov.u16 	%rs44, 0;
	@%p90 bra 	$L__BB0_115;

	abs.f32 	%f329, %f82;
	setp.lt.f32 	%p91, %f329, 0f7F800000;
	selp.u16 	%rs44, 1, 0, %p91;

$L__BB0_115:
	setp.ne.s16 	%p92, %rs44, 0;
	@%p92 bra 	$L__BB0_117;

	mov.u64 	%rd323, $str$6;
	cvta.global.u64 	%rd324, %rd323;
	st.local.u64 	[%rd10], %rd324;
	mov.u32 	%r556, 56;
	st.local.u32 	[%rd10+8], %r556;
	mov.u64 	%rd325, $str$5;
	cvta.global.u64 	%rd326, %rd325;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd326;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd107;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r557, [retval0+0];
	} // callseq 27
	mov.u64 	%rd328, $str$8;
	cvta.global.u64 	%rd329, %rd328;
	mov.u64 	%rd330, $str$7;
	cvta.global.u64 	%rd331, %rd330;
	st.local.v2.u64 	[%rd5], {%rd331, %rd329};
	cvt.f64.f32 	%fd1, %f80;
	cvt.f64.f32 	%fd2, %f79;
	st.local.v2.f64 	[%rd5+16], {%fd2, %fd1};
	cvt.f64.f32 	%fd3, %f82;
	cvt.f64.f32 	%fd4, %f81;
	st.local.v2.f64 	[%rd5+32], {%fd4, %fd3};
	mov.u64 	%rd332, $str$12;
	cvta.global.u64 	%rd333, %rd332;
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd333;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r558, [retval0+0];
	} // callseq 28
	ld.global.v2.u32 	{%r894, %r560}, [%rd7+32];
	ld.global.u64 	%rd459, [%rd7+-24];
	mul.lo.s32 	%r891, %r894, %r37;
	mad.lo.s32 	%r893, %r560, %r894, -1;

$L__BB0_117:
	add.s32 	%r562, %r891, %r40;
	min.u32 	%r563, %r562, %r893;
	mul.wide.s32 	%rd335, %r563, 16;
	add.s64 	%rd336, %rd459, %rd335;
	ld.v4.f32 	{%f330, %f331, %f332, %f333}, [%rd336];
	mul.f32 	%f338, %f75, %f330;
	mul.f32 	%f339, %f75, %f331;
	mul.f32 	%f340, %f75, %f332;
	mul.f32 	%f341, %f75, %f333;
	mul.f32 	%f83, %f78, %f338;
	mul.f32 	%f84, %f78, %f339;
	mul.f32 	%f85, %f78, %f340;
	mul.f32 	%f86, %f78, %f341;
	setp.ltu.f32 	%p93, %f83, 0f00000000;
	mov.u16 	%rs49, 0;
	mov.u16 	%rs45, %rs49;
	@%p93 bra 	$L__BB0_119;

	abs.f32 	%f342, %f83;
	setp.lt.f32 	%p94, %f342, 0f7F800000;
	selp.u16 	%rs45, 1, 0, %p94;

$L__BB0_119:
	setp.eq.s16 	%p95, %rs45, 0;
	@%p95 bra 	$L__BB0_129;

	setp.ltu.f32 	%p96, %f84, 0f00000000;
	mov.u16 	%rs49, 0;
	mov.u16 	%rs46, %rs49;
	@%p96 bra 	$L__BB0_122;

	abs.f32 	%f343, %f84;
	setp.lt.f32 	%p97, %f343, 0f7F800000;
	selp.u16 	%rs46, 1, 0, %p97;

$L__BB0_122:
	setp.eq.s16 	%p98, %rs46, 0;
	@%p98 bra 	$L__BB0_129;

	setp.ltu.f32 	%p99, %f85, 0f00000000;
	mov.u16 	%rs49, 0;
	mov.u16 	%rs47, %rs49;
	@%p99 bra 	$L__BB0_125;

	abs.f32 	%f344, %f85;
	setp.lt.f32 	%p100, %f344, 0f7F800000;
	selp.u16 	%rs47, 1, 0, %p100;

$L__BB0_125:
	setp.eq.s16 	%p101, %rs47, 0;
	@%p101 bra 	$L__BB0_129;

	setp.ltu.f32 	%p102, %f86, 0f00000000;
	mov.u16 	%rs49, 0;
	@%p102 bra 	$L__BB0_129;

	abs.f32 	%f345, %f86;
	setp.lt.f32 	%p103, %f345, 0f7F800000;
	selp.u16 	%rs49, 1, 0, %p103;

$L__BB0_129:
	setp.ne.s16 	%p104, %rs49, 0;
	@%p104 bra 	$L__BB0_131;

	mov.u64 	%rd337, $str$6;
	cvta.global.u64 	%rd338, %rd337;
	st.local.u64 	[%rd10], %rd338;
	mov.u32 	%r564, 58;
	st.local.u32 	[%rd10+8], %r564;
	mov.u64 	%rd339, $str$5;
	cvta.global.u64 	%rd340, %rd339;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd340;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd107;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r565, [retval0+0];
	} // callseq 29
	mov.u64 	%rd342, $str$8;
	cvta.global.u64 	%rd343, %rd342;
	mov.u64 	%rd344, $str$9;
	cvta.global.u64 	%rd345, %rd344;
	st.local.v2.u64 	[%rd5], {%rd345, %rd343};
	cvt.f64.f32 	%fd5, %f84;
	cvt.f64.f32 	%fd6, %f83;
	st.local.v2.f64 	[%rd5+16], {%fd6, %fd5};
	cvt.f64.f32 	%fd7, %f86;
	cvt.f64.f32 	%fd8, %f85;
	st.local.v2.f64 	[%rd5+32], {%fd8, %fd7};
	mov.u64 	%rd346, $str$12;
	cvta.global.u64 	%rd347, %rd346;
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd347;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r566, [retval0+0];
	} // callseq 30
	ld.global.v2.u32 	{%r894, %r568}, [%rd7+32];
	ld.global.u64 	%rd459, [%rd7+-24];
	mad.lo.s32 	%r893, %r568, %r894, -1;

$L__BB0_131:
	mul.lo.s32 	%r896, %r894, %r38;
	add.s32 	%r570, %r896, %r39;
	min.u32 	%r571, %r570, %r893;
	mul.wide.s32 	%rd349, %r571, 16;
	add.s64 	%rd350, %rd459, %rd349;
	ld.v4.f32 	{%f346, %f347, %f348, %f349}, [%rd350];
	mul.f32 	%f354, %f77, %f346;
	mul.f32 	%f355, %f77, %f347;
	mul.f32 	%f356, %f77, %f348;
	mul.f32 	%f357, %f77, %f349;
	mul.f32 	%f87, %f76, %f354;
	mul.f32 	%f88, %f76, %f355;
	mul.f32 	%f89, %f76, %f356;
	mul.f32 	%f90, %f76, %f357;
	setp.ltu.f32 	%p105, %f87, 0f00000000;
	mov.u16 	%rs50, 0;
	@%p105 bra 	$L__BB0_133;

	abs.f32 	%f358, %f87;
	setp.lt.f32 	%p106, %f358, 0f7F800000;
	selp.u16 	%rs50, 1, 0, %p106;

$L__BB0_133:
	setp.eq.s16 	%p107, %rs50, 0;
	@%p107 bra 	$L__BB0_139;

	setp.ltu.f32 	%p109, %f88, 0f00000000;
	mov.pred 	%p207, -1;
	@%p109 bra 	$L__BB0_136;

	abs.f32 	%f359, %f88;
	setp.geu.f32 	%p207, %f359, 0f7F800000;

$L__BB0_136:
	setp.ltu.f32 	%p110, %f89, 0f00000000;
	or.pred  	%p111, %p207, %p110;
	@%p111 bra 	$L__BB0_139;

	abs.f32 	%f360, %f89;
	setp.geu.f32 	%p112, %f360, 0f7F800000;
	setp.ltu.f32 	%p113, %f90, 0f00000000;
	or.pred  	%p114, %p112, %p113;
	@%p114 bra 	$L__BB0_139;

	abs.f32 	%f361, %f90;
	setp.lt.f32 	%p115, %f361, 0f7F800000;
	@%p115 bra 	$L__BB0_140;

$L__BB0_139:
	mov.u64 	%rd351, $str$6;
	cvta.global.u64 	%rd352, %rd351;
	st.local.u64 	[%rd10], %rd352;
	mov.u32 	%r572, 60;
	st.local.u32 	[%rd10+8], %r572;
	mov.u64 	%rd353, $str$5;
	cvta.global.u64 	%rd354, %rd353;
	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd354;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd107;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r573, [retval0+0];
	} // callseq 31
	mov.u64 	%rd356, $str$8;
	cvta.global.u64 	%rd357, %rd356;
	mov.u64 	%rd358, $str$10;
	cvta.global.u64 	%rd359, %rd358;
	st.local.v2.u64 	[%rd5], {%rd359, %rd357};
	cvt.f64.f32 	%fd9, %f88;
	cvt.f64.f32 	%fd10, %f87;
	st.local.v2.f64 	[%rd5+16], {%fd10, %fd9};
	cvt.f64.f32 	%fd11, %f90;
	cvt.f64.f32 	%fd12, %f89;
	st.local.v2.f64 	[%rd5+32], {%fd12, %fd11};
	mov.u64 	%rd360, $str$12;
	cvta.global.u64 	%rd361, %rd360;
	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd361;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r574, [retval0+0];
	} // callseq 32
	ld.global.v2.u32 	{%r575, %r576}, [%rd7+32];
	ld.global.u64 	%rd459, [%rd7+-24];
	mul.lo.s32 	%r896, %r575, %r38;
	mad.lo.s32 	%r893, %r576, %r575, -1;

$L__BB0_140:
	add.s32 	%r579, %r896, %r40;
	min.u32 	%r580, %r579, %r893;
	mul.wide.s32 	%rd363, %r580, 16;
	add.s64 	%rd364, %rd459, %rd363;
	ld.v4.f32 	{%f362, %f363, %f364, %f365}, [%rd364];
	mul.f32 	%f370, %f75, %f362;
	mul.f32 	%f371, %f75, %f363;
	mul.f32 	%f372, %f75, %f364;
	mul.f32 	%f373, %f75, %f365;
	mul.f32 	%f91, %f76, %f370;
	mul.f32 	%f92, %f76, %f371;
	mul.f32 	%f93, %f76, %f372;
	mul.f32 	%f94, %f76, %f373;
	setp.ltu.f32 	%p116, %f91, 0f00000000;
	@%p116 bra 	$L__BB0_145;

	abs.f32 	%f374, %f91;
	setp.geu.f32 	%p117, %f374, 0f7F800000;
	setp.ltu.f32 	%p118, %f92, 0f00000000;
	or.pred  	%p119, %p118, %p117;
	@%p119 bra 	$L__BB0_145;

	abs.f32 	%f375, %f92;
	setp.geu.f32 	%p120, %f375, 0f7F800000;
	setp.ltu.f32 	%p121, %f93, 0f00000000;
	or.pred  	%p122, %p121, %p120;
	@%p122 bra 	$L__BB0_145;

	abs.f32 	%f376, %f93;
	setp.geu.f32 	%p123, %f376, 0f7F800000;
	setp.ltu.f32 	%p124, %f94, 0f00000000;
	or.pred  	%p125, %p124, %p123;
	@%p125 bra 	$L__BB0_145;

	abs.f32 	%f377, %f94;
	setp.lt.f32 	%p126, %f377, 0f7F800000;
	@%p126 bra 	$L__BB0_146;

$L__BB0_145:
	mov.u64 	%rd365, $str$6;
	cvta.global.u64 	%rd366, %rd365;
	st.local.u64 	[%rd10], %rd366;
	mov.u32 	%r581, 62;
	st.local.u32 	[%rd10+8], %r581;
	mov.u64 	%rd367, $str$5;
	cvta.global.u64 	%rd368, %rd367;
	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd368;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd107;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r582, [retval0+0];
	} // callseq 33
	mov.u64 	%rd370, $str$8;
	cvta.global.u64 	%rd371, %rd370;
	mov.u64 	%rd372, $str$11;
	cvta.global.u64 	%rd373, %rd372;
	st.local.v2.u64 	[%rd5], {%rd373, %rd371};
	cvt.f64.f32 	%fd13, %f92;
	cvt.f64.f32 	%fd14, %f91;
	st.local.v2.f64 	[%rd5+16], {%fd14, %fd13};
	cvt.f64.f32 	%fd15, %f94;
	cvt.f64.f32 	%fd16, %f93;
	st.local.v2.f64 	[%rd5+32], {%fd16, %fd15};
	mov.u64 	%rd374, $str$12;
	cvta.global.u64 	%rd375, %rd374;
	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd375;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r583, [retval0+0];
	} // callseq 34

$L__BB0_146:
	ld.global.u8 	%rs38, [%rd7+44];
	and.b16  	%rs39, %rs38, 32;
	setp.ne.s16 	%p127, %rs39, 0;
	@%p127 bra 	$L__BB0_159;

	ld.global.f32 	%f95, [%rd7+28];
	setp.eq.f32 	%p128, %f95, 0f3F800000;
	@%p128 bra 	$L__BB0_153;

	mov.f32 	%f378, 0f00000000;
	div.rn.f32 	%f379, %f378, %f95;
	add.f32 	%f380, %f34, %f379;
	setp.lt.f32 	%p129, %f380, 0f00000000;
	setp.gt.f32 	%p130, %f380, 0f3F800000;
	selp.f32 	%f381, 0f3F800000, %f380, %p130;
	mul.f32 	%f382, %f381, 0f40490FDB;
	selp.f32 	%f96, 0f00000000, %f382, %p129;
	abs.f32 	%f383, %f96;
	setp.leu.f32 	%p131, %f383, 0f47CE4780;
	setp.eq.f32 	%p132, %f383, 0f7F800000;
	or.pred  	%p133, %p131, %p132;
	@%p133 bra 	$L__BB0_153;

	mov.b32 	%r585, %f96;
	shl.b32 	%r586, %r585, 8;
	or.b32  	%r58, %r586, -2147483648;
	mov.u64 	%rd463, 0;
	mov.u32 	%r897, 0;
	mov.u64 	%rd461, __cudart_i2opi_f;
	mov.u64 	%rd462, %rd1;

$L__BB0_150:
	.pragma "nounroll";
	ld.global.nc.u32 	%r587, [%rd461];
	mad.wide.u32 	%rd379, %r587, %r58, %rd463;
	shr.u64 	%rd463, %rd379, 32;
	st.local.u32 	[%rd462], %rd379;
	add.s64 	%rd462, %rd462, 4;
	add.s64 	%rd461, %rd461, 4;
	add.s32 	%r897, %r897, 1;
	setp.ne.s32 	%p134, %r897, 6;
	@%p134 bra 	$L__BB0_150;

	add.s64 	%rd448, %rd1, 24;
	st.local.u32 	[%rd448], %rd463;

$L__BB0_153:
	@%p128 bra 	$L__BB0_159;

	rcp.rn.f32 	%f384, %f95;
	add.f32 	%f385, %f34, %f384;
	setp.lt.f32 	%p136, %f385, 0f00000000;
	setp.gt.f32 	%p137, %f385, 0f3F800000;
	selp.f32 	%f386, 0f3F800000, %f385, %p137;
	mul.f32 	%f387, %f386, 0f40490FDB;
	selp.f32 	%f97, 0f00000000, %f387, %p136;
	abs.f32 	%f388, %f97;
	setp.leu.f32 	%p138, %f388, 0f47CE4780;
	setp.eq.f32 	%p139, %f388, 0f7F800000;
	or.pred  	%p140, %p138, %p139;
	@%p140 bra 	$L__BB0_159;

	mov.b32 	%r589, %f97;
	shl.b32 	%r590, %r589, 8;
	or.b32  	%r61, %r590, -2147483648;
	mov.u64 	%rd466, 0;
	mov.u32 	%r898, 0;
	mov.u64 	%rd464, __cudart_i2opi_f;
	mov.u64 	%rd465, %rd1;

$L__BB0_156:
	.pragma "nounroll";
	ld.global.nc.u32 	%r591, [%rd464];
	mad.wide.u32 	%rd382, %r591, %r61, %rd466;
	shr.u64 	%rd466, %rd382, 32;
	st.local.u32 	[%rd465], %rd382;
	add.s64 	%rd465, %rd465, 4;
	add.s64 	%rd464, %rd464, 4;
	add.s32 	%r898, %r898, 1;
	setp.ne.s32 	%p141, %r898, 6;
	@%p141 bra 	$L__BB0_156;

	add.s64 	%rd449, %rd1, 24;
	st.local.u32 	[%rd449], %rd466;

$L__BB0_159:
	fma.rn.f32 	%f576, %f33, 0f40000000, 0fBF800000;
	fma.rn.f32 	%f577, %f34, 0f40000000, 0fBF800000;

$L__BB0_192:
	mul.f32 	%f434, %f576, %f259;
	fma.rn.f32 	%f435, %f240, %f434, %f596;
	fma.rn.f32 	%f436, %f434, %f241, %f597;
	fma.rn.f32 	%f437, %f434, %f242, %f598;
	mul.f32 	%f438, %f577, %f259;
	fma.rn.f32 	%f136, %f438, %f246, %f435;
	fma.rn.f32 	%f137, %f438, %f247, %f436;
	fma.rn.f32 	%f138, %f438, %f248, %f437;
	mul.f32 	%f439, %f601, %f257;
	fma.rn.f32 	%f440, %f600, %f256, %f439;
	fma.rn.f32 	%f441, %f602, %f258, %f440;
	ld.const.f32 	%f442, [global+156];
	div.rn.f32 	%f443, %f442, %f441;
	fma.rn.f32 	%f444, %f600, %f443, %f596;
	fma.rn.f32 	%f445, %f601, %f443, %f597;
	fma.rn.f32 	%f446, %f602, %f443, %f598;
	sub.f32 	%f447, %f444, %f136;
	sub.f32 	%f448, %f445, %f137;
	sub.f32 	%f449, %f446, %f138;
	mul.f32 	%f450, %f448, %f448;
	fma.rn.f32 	%f451, %f447, %f447, %f450;
	fma.rn.f32 	%f452, %f449, %f449, %f451;
	sqrt.rn.f32 	%f453, %f452;
	div.rn.f32 	%f600, %f447, %f453;
	div.rn.f32 	%f601, %f448, %f453;
	div.rn.f32 	%f602, %f449, %f453;
	mov.f32 	%f596, %f136;
	mov.f32 	%f597, %f137;
	mov.f32 	%f598, %f138;

$L__BB0_193:
	mov.f32 	%f603, 0f7F7FFFFF;
	mov.f32 	%f599, 0f38D1B717;

$L__BB0_243:
	ld.const.u64 	%rd443, [global+8];
	mov.f32 	%f604, 0f00000000;
	mov.u32 	%r811, 255;
	mov.u32 	%r816, 1;
	mov.u32 	%r817, 0;
	// begin inline asm
	call(%r778,%r779,%r780,%r781,%r782,%r783,%r784,%r785,%r786,%r787,%r788,%r789,%r790,%r791,%r792,%r793,%r794,%r795,%r796,%r797,%r798,%r799,%r800,%r801,%r802,%r803,%r804,%r805,%r806,%r807,%r808,%r809),_optix_trace_typed_32,(%r817,%rd443,%f596,%f597,%f598,%f600,%f601,%f602,%f599,%f603,%f604,%r811,%r816,%r817,%r817,%r817,%r816,%r817,%r849,%r850,%r851,%r852,%r853,%r854,%r855,%r856,%r857,%r858,%r859,%r860,%r861,%r862,%r863,%r864,%r865,%r866,%r867,%r868,%r869,%r870,%r871,%r872,%r873,%r874,%r875,%r876,%r877,%r878,%r879);
	// end inline asm
	setp.eq.s32 	%p206, %r778, 0;
	mov.f32 	%f605, %f604;
	mov.f32 	%f606, %f604;
	@%p206 bra 	$L__BB0_245;

	mov.b32 	%f541, %r778;
	div.rn.f32 	%f542, %f541, 0f40A00000;
	mul.f32 	%f543, %f542, %f542;
	fma.rn.f32 	%f544, %f1, 0f3F000000, 0f3F000000;
	mul.f32 	%f604, %f544, %f543;
	fma.rn.f32 	%f545, %f2, 0f3F000000, 0f3F000000;
	mul.f32 	%f605, %f545, %f543;
	mov.f32 	%f606, 0f3F800000;

$L__BB0_245:
	mul.f32 	%f546, %f605, 0f3EB714BA;
	fma.rn.f32 	%f547, %f604, 0f3ED32D0A, %f546;
	mul.f32 	%f548, %f605, 0f3F3714BA;
	fma.rn.f32 	%f549, %f604, 0f3E59C66D, %f548;
	mul.f32 	%f550, %f605, 0f3DF41B76;
	fma.rn.f32 	%f551, %f604, 0f3C9E6256, %f550;
	ld.const.u64 	%rd444, [global];
	cvta.to.global.u64 	%rd445, %rd444;
	mul.wide.u32 	%rd446, %r1, 16;
	add.s64 	%rd447, %rd445, %rd446;
	fma.rn.f32 	%f552, %f606, 0f3F734214, %f551;
	fma.rn.f32 	%f553, %f606, 0f3D93CD57, %f549;
	fma.rn.f32 	%f554, %f606, 0f3E38C0CF, %f547;
	mov.f32 	%f555, 0f3F800000;
	st.global.v4.f32 	[%rd447], {%f554, %f553, %f552, %f555};
	ret;

}
	// .globl	__closesthit__main_closest_hit
.visible .entry __closesthit__main_closest_hit()
{
	.reg .f32 	%f<2>;
	.reg .b32 	%r<3>;


	// begin inline asm
	call (%f1), _optix_get_ray_tmax, ();
	// end inline asm
	mov.b32 	%r2, %f1;
	mov.u32 	%r1, 0;
	// begin inline asm
	call _optix_set_payload, (%r1, %r2);
	// end inline asm
	ret;

}
	// .globl	__miss__main_miss
.visible .entry __miss__main_miss()
{



	ret;

}
	// .globl	__closesthit__env_closest_hit
.visible .entry __closesthit__env_closest_hit()
{



	ret;

}
	// .globl	__miss__env_miss
.visible .entry __miss__env_miss()
{



	ret;

}

